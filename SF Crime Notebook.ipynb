{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook contains our solution to the Kaggle SF Crime problem\n",
    "https://www.kaggle.com/c/sf-crime\n",
    "\n",
    "We started with a basic exploration of the data.\n",
    "- Count unique values for each variable\n",
    "- View most common values\n",
    "- XY plot of lat/long w. circles to indicate number of crimes\n",
    "- Time series plots to see how category use changes over time\n",
    "\n",
    "Interesting Points:\n",
    "- Most crime on Friday, then Wednesday. Least on Sunday.\n",
    "- X and Y latitude have same number of distinct values. Seem to be somehow linked to locations\n",
    "  since, despite there being a lots of sig fig, they still can be frequency counted\n",
    "- 800 Block of BRYANT ST has 4x+ more data points than anyplace else. Seems to link w/ most freq X and Y\n",
    "- \"Other Offenses\" are common\n",
    "- The dates with the most crime are new years day. Also the first of months.\n",
    "- Note: Strange max value of Y = 90 for 67 values. These appear to be in Chicago, but the data has addresses in SF. We removed this data from our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 878,049, values.\n",
      "There are a total of 389,257 Dates.\n",
      "There are a total of 39 Category.\n",
      "There are a total of 879 Descript.\n",
      "There are a total of 7 DayOfWeek.\n",
      "There are a total of 10 PdDistrict.\n",
      "There are a total of 17 Resolution.\n",
      "There are a total of 23,228 Address.\n",
      "There are a total of 34,243 X.\n",
      "There are a total of 34,243 Y.\n",
      "-------------------------------------------------------------------------\n",
      "There are a total of 39 distinct Category values, as follows: \n",
      "LARCENY/THEFT                  0.199192\n",
      "OTHER OFFENSES                 0.143707\n",
      "NON-CRIMINAL                   0.105124\n",
      "ASSAULT                        0.087553\n",
      "DRUG/NARCOTIC                  0.061467\n",
      "VEHICLE THEFT                  0.061251\n",
      "VANDALISM                      0.050937\n",
      "WARRANTS                       0.048077\n",
      "BURGLARY                       0.041860\n",
      "SUSPICIOUS OCC                 0.035777\n",
      "MISSING PERSON                 0.029599\n",
      "ROBBERY                        0.026194\n",
      "FRAUD                          0.018996\n",
      "FORGERY/COUNTERFEITING         0.012082\n",
      "SECONDARY CODES                0.011372\n",
      "WEAPON LAWS                    0.009743\n",
      "PROSTITUTION                   0.008523\n",
      "TRESPASS                       0.008343\n",
      "STOLEN PROPERTY                0.005171\n",
      "SEX OFFENSES FORCIBLE          0.004997\n",
      "DISORDERLY CONDUCT             0.004920\n",
      "DRUNKENNESS                    0.004874\n",
      "RECOVERED VEHICLE              0.003574\n",
      "KIDNAPPING                     0.002666\n",
      "DRIVING UNDER THE INFLUENCE    0.002583\n",
      "RUNAWAY                        0.002216\n",
      "LIQUOR LAWS                    0.002167\n",
      "ARSON                          0.001723\n",
      "LOITERING                      0.001395\n",
      "EMBEZZLEMENT                   0.001328\n",
      "SUICIDE                        0.000579\n",
      "FAMILY OFFENSES                0.000559\n",
      "BAD CHECKS                     0.000462\n",
      "BRIBERY                        0.000329\n",
      "EXTORTION                      0.000292\n",
      "SEX OFFENSES NON FORCIBLE      0.000169\n",
      "GAMBLING                       0.000166\n",
      "PORNOGRAPHY/OBSCENE MAT        0.000025\n",
      "TREA                           0.000007\n",
      "dtype: float64\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "There are a total of 10 distinct PdDistrict values, as follows: \n",
      "SOUTHERN      0.179013\n",
      "MISSION       0.136562\n",
      "NORTHERN      0.119920\n",
      "BAYVIEW       0.101852\n",
      "CENTRAL       0.097329\n",
      "TENDERLOIN    0.093171\n",
      "INGLESIDE     0.089796\n",
      "TARAVAL       0.074707\n",
      "PARK          0.056162\n",
      "RICHMOND      0.051488\n",
      "dtype: float64\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "There are a total of 17 distinct Resolution values, as follows: \n",
      "NONE                                      0.599955\n",
      "ARREST, BOOKED                            0.235070\n",
      "ARREST, CITED                             0.087699\n",
      "LOCATED                                   0.019476\n",
      "PSYCHOPATHIC CASE                         0.016553\n",
      "UNFOUNDED                                 0.010916\n",
      "JUVENILE BOOKED                           0.006337\n",
      "COMPLAINANT REFUSES TO PROSECUTE          0.004528\n",
      "DISTRICT ATTORNEY REFUSES TO PROSECUTE    0.004480\n",
      "NOT PROSECUTED                            0.004230\n",
      "JUVENILE CITED                            0.003795\n",
      "PROSECUTED BY OUTSIDE AGENCY              0.002852\n",
      "EXCEPTIONAL CLEARANCE                     0.001742\n",
      "JUVENILE ADMONISHED                       0.001657\n",
      "JUVENILE DIVERTED                         0.000404\n",
      "CLEARED-CONTACT JUVENILE FOR MORE INFO    0.000247\n",
      "PROSECUTED FOR LESSER OFFENSE             0.000058\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_orig = pd.read_csv(\"train.csv\")\n",
    "test_orig = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Count distinct for each variable:\n",
    "print \"There are a total of {:,}, values.\".format(len(data_orig))\n",
    "\n",
    "for var, series in data_orig.iteritems():\n",
    "    print \"There are a total of {:,} {}.\".format(len(series.value_counts()), var)\n",
    "# View All of Categories, PdDistrict, Resolution, DayOfWeek\n",
    "variables = [\"Category\", \"PdDistrict\", \"Resolution\"]\n",
    "x = data_orig[\"Category\"].value_counts()/len(data_orig)\n",
    "for col in variables:\n",
    "    print \"-------------------------------------------------------------------------\"\n",
    "    print \"There are a total of {:,} distinct {} values, as follows: \".format(len(data_orig[col].value_counts()), col)\n",
    "    print data_orig[col].value_counts()/len(data_orig)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did more of this type of analysis but are showing only a sample for this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_clean = data_orig[data_orig.Y != 90]\n",
    "stk_list = ['LARCENY/THEFT','OTHER OFFENSES','NON-CRIMINAL','ASSAULT']\n",
    "data = data_clean[data_clean.Category.isin(stk_list)]\n",
    "\n",
    "def add_date_vars(df):\n",
    "    df.loc[:, ('Dates')] = pd.to_datetime(df.loc[:, ('Dates')])\n",
    "    df.loc[:, ('Year')] = df.Dates.dt.year\n",
    "    df.loc[:, ('Month')] = df.Dates.dt.month\n",
    "    df.loc[:, ('Day')] = df.Dates.dt.day\n",
    "    df.loc[:, ('Date')] = df.Dates.dt.date\n",
    "    df.loc[:, ('Hour')] = df.Dates.dt.hour\n",
    "    df.loc[:, ('DayOfYear')] = df.Dates.dt.dayofyear\n",
    "    df.loc[:, ('WeekDay')] = df.Dates.dt.weekday\n",
    "    \n",
    "    datetime_vector = pd.to_datetime(df['Dates'])\n",
    "    date_vector = datetime_vector.dt.date\n",
    "    date_diff_vector = (date_vector - date_vector.min()) / np.timedelta64(1, 'D')\n",
    "    df.loc[:, ('DateDiff')] = date_diff_vector\n",
    "\n",
    "add_date_vars(data)\n",
    "add_date_vars(test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create random dev sample so we can see how that accuracy compares to our Kaggle results\n",
    "np.random.seed(100)\n",
    "\n",
    "rows = np.random.choice(data.index, size = len(data) / 10, replace = False)\n",
    "\n",
    "dev = data.ix[rows]\n",
    "train = data.drop(rows)\n",
    "\n",
    "# Convert to Numpy Format with only DateDiff, X and Y features\n",
    "train_data = np.array(train[['DateDiff','X','Y']].values)\n",
    "train_labels = np.array(train[['Category']].values.ravel())\n",
    "\n",
    "dev_data = np.array(dev[['DateDiff','X','Y']].values)\n",
    "dev_labels = np.array(dev[['Category']].values.ravel())\n",
    "\n",
    "full_data = np.array(data[['DateDiff','X','Y']].values)\n",
    "full_labels = np.array(data[['Category']].values.ravel())\n",
    "\n",
    "test_data = np.array(test_orig[['DateDiff','X','Y']].values)\n",
    "\n",
    "# Normalize Data to Between 0-1\n",
    "#a + (x-A)*(b-a)/(B-A) \n",
    "train_normed = 0 + (np.abs(train_data) - np.abs(train_data).min(axis=0))*(1-0)/(np.abs(train_data).max(axis=0) - np.abs(train_data).min(axis=0)) \n",
    "dev_normed = 0 + (np.abs(dev_data) - np.abs(dev_data).min(axis=0))*(1-0)/(np.abs(dev_data).max(axis=0) - np.abs(dev_data).min(axis=0)) \n",
    "test_normed = 0 + (np.abs(test_data) - np.abs(train_data).min(axis=0))*(1-0)/(np.abs(train_data).max(axis=0) - np.abs(train_data).min(axis=0)) \n",
    "full_normed = 0 + (np.abs(full_data) - np.abs(train_data).min(axis=0))*(1-0)/(np.abs(train_data).max(axis=0) - np.abs(train_data).min(axis=0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function that will create a correctly formatted output file for submission to Kaggle.\n",
    "\n",
    "def create_submission(preds):\n",
    "    labels = [\"Id\",\"ARSON\",\"ASSAULT\",\"BAD CHECKS\",\"BRIBERY\",\"BURGLARY\",\"DISORDERLY CONDUCT\",\"DRIVING UNDER THE INFLUENCE\",\n",
    "              \"DRUG/NARCOTIC\",\"DRUNKENNESS\",\"EMBEZZLEMENT\",\"EXTORTION\",\"FAMILY OFFENSES\",\"FORGERY/COUNTERFEITING\",\n",
    "              \"FRAUD\",\"GAMBLING\",\"KIDNAPPING\",\"LARCENY/THEFT\",\"LIQUOR LAWS\",\"LOITERING\",\"MISSING PERSON\",\"NON-CRIMINAL\",\n",
    "              \"OTHER OFFENSES\",\"PORNOGRAPHY/OBSCENE MAT\",\"PROSTITUTION\",\"RECOVERED VEHICLE\",\"ROBBERY\",\"RUNAWAY\",\n",
    "              \"SECONDARY CODES\",\"SEX OFFENSES FORCIBLE\",\"SEX OFFENSES NON FORCIBLE\",\"STOLEN PROPERTY\",\"SUICIDE\",\n",
    "              \"SUSPICIOUS OCC\",\"TREA\",\"TRESPASS\",\"VANDALISM\",\"VEHICLE THEFT\",\"WARRANTS\",\"WEAPON LAWS\"]\n",
    "    head_str = ','.join(labels)\n",
    "\n",
    "    num_cats = len(labels)\n",
    "    \n",
    "    # Make a dummy row to append to\n",
    "    ids = np.arange(preds.shape[0])[np.newaxis].transpose()\n",
    "    \n",
    "    results = np.column_stack((ids, preds))\n",
    "\n",
    "    num_form = ['%6f'] * (num_cats - 1)\n",
    "    num_form.insert(0, '%d')\n",
    "    # Write results to csv\n",
    "    np.savetxt('sample.csv', results, fmt=num_form, delimiter=',', header=head_str, comments='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model was a simple KNN model. We tried a variety of N's for neighbors and both normalized and regular data. We also looked at just including a subset of crimes for it to predict. In the end, we chose N=1, normalized data, and the top 4 crimes. One problem with KNN was that it predicted 1's and 0's, which resulted in a low score (27). For the final KNN submission, we replaced the 0's with average probability of the crime. This submission got a score of 2.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for each k value was [mean: 0.22013, std: 0.03731, params: {'n_neighbors': 1}, mean: 0.23360, std: 0.04609, params: {'n_neighbors': 2}, mean: 0.22577, std: 0.04040, params: {'n_neighbors': 3}, mean: 0.23504, std: 0.04684, params: {'n_neighbors': 4}, mean: 0.22913, std: 0.04194, params: {'n_neighbors': 5}, mean: 0.23679, std: 0.04770, params: {'n_neighbors': 6}, mean: 0.23198, std: 0.04362, params: {'n_neighbors': 7}, mean: 0.23708, std: 0.04755, params: {'n_neighbors': 8}, mean: 0.23393, std: 0.04445, params: {'n_neighbors': 9}, mean: 0.23831, std: 0.04801, params: {'n_neighbors': 10}] \n",
      "\n",
      "The best k value was {'n_neighbors': 10} with accuracy 0.2383\n"
     ]
    }
   ],
   "source": [
    "# Use GridSearchCV to find a good number of neighbors.\n",
    "\n",
    "ks = {'n_neighbors': [1,2,3,4,5,6,7,8,9,10]}\n",
    "KNNGridSearch = GridSearchCV(KNeighborsClassifier(), ks, scoring='accuracy')\n",
    "KNNGridSearch.fit(train_normed, train_labels)\n",
    "\n",
    "# Report out on the accuracies    \n",
    "print \"The scores for each k value was %s \" % (KNNGridSearch.grid_scores_)\n",
    "print \"\\nThe best k value was %s with accuracy %.4f\" % (KNNGridSearch.best_params_, KNNGridSearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now that we've done this, let's run the KNN on the full train, apply to the test, then format.\n",
    "\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=1)\n",
    "KNNmodel.fit(full_normed, full_labels)\n",
    "dev_predict = KNNmodel.predict_proba(test_normed).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should note that entering the other 35 categories with their average probability was done by hand in Excel. We looked at doing it in python, but realized we wanted to pursue other models instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model was logistic regression. We tried several values of C, before settling on C=0.001. This improved our score to 2.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYWZmhRwgzMyskAOEmZkV+v8z8hfWMxf65gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2845ba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "fmt has wrong shape.  ['%d', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-65e275c72acc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_normed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtest_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_normed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_submission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Logistic Regression accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_normed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-1ac66fee88b0>\u001b[0m in \u001b[0;36mcreate_submission\u001b[1;34m(preds)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mnum_form\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Write results to csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_form\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Miki\\Miniconda\\lib\\site-packages\\numpy\\lib\\npyio.pyc\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mncol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1055\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fmt has wrong shape.  %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1056\u001b[0m             \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: fmt has wrong shape.  ['%d', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f']"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "clf.fit(train_data, train_labels)\n",
    "print clf.best_params_\n",
    "#print clf.grid_scores_\n",
    "res = zip(*[(f1m, f1s.std(), p['C']) \n",
    "            for p, f1m, f1s in clf.grid_scores_])\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(res[2],res[0],'-o')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(res[2],res[1],'-o')\n",
    "plt.show()\n",
    "\n",
    "model = LogisticRegression(C=0.001)\n",
    "model.fit(train_normed, train_labels)\n",
    "test_predict = model.predict_proba(test_normed)\n",
    "results = create_submission(test_predict)\n",
    "\n",
    "print \"Logistic Regression accuracy:\", model.score(dev_normed, dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, model.predict_proba(dev_normed)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "fmt has wrong shape.  ['%d', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bc44544b5548>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_normed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_submission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-1ac66fee88b0>\u001b[0m in \u001b[0;36mcreate_submission\u001b[1;34m(preds)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mnum_form\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Write results to csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_form\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Miki\\Miniconda\\lib\\site-packages\\numpy\\lib\\npyio.pyc\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mncol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1055\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fmt has wrong shape.  %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1056\u001b[0m             \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: fmt has wrong shape.  ['%d', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f', '%6f']"
     ]
    }
   ],
   "source": [
    "test_predict = model.predict_proba(test_normed)\n",
    "create_submission(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting this model, we tried averaging the KNN and LR in various ways, but that did not improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bernoulli Naive Bayes\n",
    "##Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BernoulliNB requires binary data, so we created dummy variables for each variable in the data set (all date and district variables). We also left all variables in the data set so that we could include and exclude features in our models easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract new features here because it's easier in Pandas than NumPy\n",
    "def time_features(data):\n",
    "    data['DateTime'] = pd.to_datetime(data['Dates'])\n",
    "    data['Year'] = pd.DatetimeIndex(data['DateTime']).year\n",
    "    data['Month'] = pd.DatetimeIndex(data['DateTime']).month\n",
    "    data['Day'] = pd.DatetimeIndex(data['DateTime']).day\n",
    "    data['Hour'] = pd.DatetimeIndex(data['DateTime']).hour\n",
    "    data['SecondsDelta'] = (data.DateTime - pd.Timestamp('2013-01-01')) / np.timedelta64(1,'s')\n",
    "    data['Weekend'] = (data.DayOfWeek == \"Saturday\") | (data.DayOfWeek == \"Sunday\")\n",
    "    years = pd.get_dummies(data.Year)\n",
    "    months = pd.get_dummies(data.Month)\n",
    "    months.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    days = pd.get_dummies(data.Day)\n",
    "    daysofweek = pd.get_dummies(data.DayOfWeek)\n",
    "    hours = pd.get_dummies(data.Hour)\n",
    "    hours.columns = ['12AM', '1AM', '2AM', '3AM', '4AM', '5AM',\n",
    "                     '6AM', '7AM', '8AM', '9AM', '10AM', '11AM',\n",
    "                     '12PM', '1PM', '2PM', '3PM', '4PM', '5PM',\n",
    "                     '6PM', '7PM', '8PM', '9PM', '10PM', '11PM']\n",
    "    districts = pd.get_dummies(data.PdDistrict)\n",
    "    new_data = pd.concat([data, years, months, days, daysofweek, hours, districts], axis=1)\n",
    "    return new_data\n",
    "\n",
    "data = time_features(data_orig)\n",
    "test = time_features(test_orig)\n",
    "\n",
    "# Separate labels\n",
    "labels = data.Category\n",
    "\n",
    "# Drop Category, Descript and Resolution columns since we cannot use them to predict\n",
    "train_data = data.drop(['Category', 'Descript', 'Resolution'], axis=1)\n",
    "train_names = train_data.columns.values.tolist()\n",
    "test_names = test.columns.values.tolist()\n",
    "\n",
    "print data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to features.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(train_data.shape[0]))\n",
    "train_data = train_data.reindex(shuffle)\n",
    "labels = labels.reindex(shuffle)\n",
    "\n",
    "# Remove records where Y == 90\n",
    "train_data_clean = train_data[train_data.Y != 90]\n",
    "labels_clean = labels[train_data.Y != 90]\n",
    "num_examples = train_data_clean.shape[0]\n",
    "\n",
    "# Split the feature and label sets into train and dev sets\n",
    "mini_train_data = train_data_clean[:5000]\n",
    "mini_train_labels = labels_clean[:5000]\n",
    "\n",
    "reg_train_data = train_data_clean[5000:num_examples/2]\n",
    "reg_train_labels = labels_clean[5000:num_examples/2]\n",
    "\n",
    "dev_data = train_data_clean[num_examples/2:]\n",
    "dev_labels = labels_clean[num_examples/2:]\n",
    "\n",
    "test_data = test.copy()\n",
    "\n",
    "print \"Mini Train Data:\", mini_train_data.shape\n",
    "print \"Mini Train Labels:\", mini_train_labels.shape\n",
    "print \"Regular Train Data:\", reg_train_data.shape\n",
    "print \"Regular Train Labels:\", reg_train_labels.shape\n",
    "print \"Dev Data:\", dev_data.shape\n",
    "print \"Dev Labels:\", dev_labels.shape\n",
    "print \"Test Data:\", test_data.shape\n",
    "print \"Columns in use:\", train_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use = [2003L, 2004L, 2005L, 2006L, 2007L, 2008L, 2009L, 2010L, 2011L, 2012L, 2013L, 2014L, 2015L, \n",
    "                   'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', \n",
    "                   1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, \n",
    "                   16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, \n",
    "                   'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', \n",
    "                   '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', \n",
    "                   '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', \n",
    "                   'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', \n",
    "                   'SOUTHERN', 'TARAVAL', 'TENDERLOIN', 'X', 'Y'\n",
    "                   ]\n",
    "\n",
    "print \"Number of features:\", len(features_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third model used Bernoulli Naive Bayes, which scored about the same as logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's see what the optimal alpha is for a Bernoulli NB model\n",
    "\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "clf = GridSearchCV(BernoulliNB(), [params], scoring='accuracy')\n",
    "clf.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "\n",
    "print clf.best_params_\n",
    "print clf.best_score_\n",
    "\n",
    "best_alpha = clf.best_params_['alpha']\n",
    "\n",
    "accuracies = [clf.grid_scores_[i][1] * 100 for i in range(len(clf.grid_scores_))]\n",
    "\n",
    "plt.plot(np.log10(params['alpha']), accuracies, marker='o')\n",
    "plt.xlabel(\"Log(Alpha)\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we throw in 99 features (basically every feature we created), the accuracy is maximized when alpha = 10. However, the practical difference in accuracy levels is very small -- we got an improvement of 0.015% when changing alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How well does the Bernoulli NB model do with the selected alpha?\n",
    "\n",
    "bnb = BernoulliNB(alpha=best_alpha)\n",
    "bnb.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "bnb_probs = bnb.predict_proba(test_data[features_to_use])\n",
    "print \"BernoulliNB accuracy:\", bnb.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, bnb.predict_proba(dev_data[features_to_use])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maybe bagging the Bernoulli NB model does us some good\n",
    "\n",
    "bnb_bag = BaggingClassifier(BernoulliNB(alpha=best_alpha), max_features=0.8, max_samples = 0.8)\n",
    "bnb_bag.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "bnb_bag_probs = bnb_bag.predict_proba(test_data[features_to_use])\n",
    "print \"BernoulliNB with bagging accuracy:\", bnb_bag.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, bnb_bag.predict_proba(dev_data[features_to_use])) \n",
    "print \"\\n\"\n",
    "\n",
    "# Perhaps doing some dimensionality reduction will help us\n",
    "pca = PCA(n_components = 70)\n",
    "pca_train_data = pca.fit_transform(reg_train_data[features_to_use])\n",
    "pca_dev_data = pca.transform(dev_data[features_to_use])\n",
    "pca_test_data = pca.transform(test_data[features_to_use])\n",
    "\n",
    "bnb2 = BernoulliNB()\n",
    "bnb2.fit(pca_train_data, reg_train_labels)\n",
    "bnb2_probs = bnb2.predict_proba(pca_test_data)\n",
    "print \"BernoulliNB with PCA accuracy:\", bnb2.score(pca_dev_data, dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, bnb2.predict_proba(pca_dev_data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried using bagging to determine if we could get a more robust model. We also tried using PCA to reduce dimensions and using those new features in the Bernoulli NB model. However, neither of these made any significant improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried Gradient Boosting, which improved our score to 2.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try Gradient Boosting\n",
    "\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "grad_boost.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "print \"Logistic Regression accuracy:\", grad_boost.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, grad_boost.predict_proba(dev_data[features_to_use])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we used a neural net, which got our best score of 2.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try a decision tree\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "dt_probs = dt.predict_proba(test_data[features_to_use])\n",
    "print \"Decision Tree accuracy:\", dt.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, dt.predict_proba(dev_data[features_to_use])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try a random forest\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "rf_probs = rf.predict_proba(test_data[features_to_use])\n",
    "print \"Random Forest accuracy:\", rf.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, rf.predict_proba(dev_data[features_to_use])) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
