{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook contains our solution to the Kaggle SF Crime problem\n",
    "https://www.kaggle.com/c/sf-crime\n",
    "\n",
    "We started with a basic exploration of the data.\n",
    "- Count unique values for each variable\n",
    "- View most common values\n",
    "- XY plot of lat/long w. circles to indicate number of crimes\n",
    "- Time series plots to see how category use changes over time\n",
    "\n",
    "Interesting Points:\n",
    "- Most crime on Friday, then Wednesday. Least on Sunday.\n",
    "- X and Y latitude have same number of distinct values. Seem to be somehow linked to locations\n",
    "  since, despite there being a lots of sig fig, they still can be frequency counted\n",
    "- 800 Block of BRYANT ST has 4x+ more data points than anyplace else. Seems to link w/ most freq X and Y\n",
    "- \"Other Offenses\" are common\n",
    "- The dates with the most crime are new years day. Also the first of months.\n",
    "- Note: Strange max value of Y = 90 for 67 values. These appear to be in Chicago, but the data has addresses in SF. We removed this data from our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 878,049, values.\n",
      "There are a total of 389,257 Dates.\n",
      "There are a total of 39 Category.\n",
      "There are a total of 879 Descript.\n",
      "There are a total of 7 DayOfWeek.\n",
      "There are a total of 10 PdDistrict.\n",
      "There are a total of 17 Resolution.\n",
      "There are a total of 23,228 Address.\n",
      "There are a total of 34,243 X.\n",
      "There are a total of 34,243 Y.\n",
      "-------------------------------------------------------------------------\n",
      "There are a total of 39 distinct Category values, as follows: \n",
      "LARCENY/THEFT                  0.199192\n",
      "OTHER OFFENSES                 0.143707\n",
      "NON-CRIMINAL                   0.105124\n",
      "ASSAULT                        0.087553\n",
      "DRUG/NARCOTIC                  0.061467\n",
      "VEHICLE THEFT                  0.061251\n",
      "VANDALISM                      0.050937\n",
      "WARRANTS                       0.048077\n",
      "BURGLARY                       0.041860\n",
      "SUSPICIOUS OCC                 0.035777\n",
      "MISSING PERSON                 0.029599\n",
      "ROBBERY                        0.026194\n",
      "FRAUD                          0.018996\n",
      "FORGERY/COUNTERFEITING         0.012082\n",
      "SECONDARY CODES                0.011372\n",
      "WEAPON LAWS                    0.009743\n",
      "PROSTITUTION                   0.008523\n",
      "TRESPASS                       0.008343\n",
      "STOLEN PROPERTY                0.005171\n",
      "SEX OFFENSES FORCIBLE          0.004997\n",
      "DISORDERLY CONDUCT             0.004920\n",
      "DRUNKENNESS                    0.004874\n",
      "RECOVERED VEHICLE              0.003574\n",
      "KIDNAPPING                     0.002666\n",
      "DRIVING UNDER THE INFLUENCE    0.002583\n",
      "RUNAWAY                        0.002216\n",
      "LIQUOR LAWS                    0.002167\n",
      "ARSON                          0.001723\n",
      "LOITERING                      0.001395\n",
      "EMBEZZLEMENT                   0.001328\n",
      "SUICIDE                        0.000579\n",
      "FAMILY OFFENSES                0.000559\n",
      "BAD CHECKS                     0.000462\n",
      "BRIBERY                        0.000329\n",
      "EXTORTION                      0.000292\n",
      "SEX OFFENSES NON FORCIBLE      0.000169\n",
      "GAMBLING                       0.000166\n",
      "PORNOGRAPHY/OBSCENE MAT        0.000025\n",
      "TREA                           0.000007\n",
      "dtype: float64\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "There are a total of 10 distinct PdDistrict values, as follows: \n",
      "SOUTHERN      0.179013\n",
      "MISSION       0.136562\n",
      "NORTHERN      0.119920\n",
      "BAYVIEW       0.101852\n",
      "CENTRAL       0.097329\n",
      "TENDERLOIN    0.093171\n",
      "INGLESIDE     0.089796\n",
      "TARAVAL       0.074707\n",
      "PARK          0.056162\n",
      "RICHMOND      0.051488\n",
      "dtype: float64\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "There are a total of 17 distinct Resolution values, as follows: \n",
      "NONE                                      0.599955\n",
      "ARREST, BOOKED                            0.235070\n",
      "ARREST, CITED                             0.087699\n",
      "LOCATED                                   0.019476\n",
      "PSYCHOPATHIC CASE                         0.016553\n",
      "UNFOUNDED                                 0.010916\n",
      "JUVENILE BOOKED                           0.006337\n",
      "COMPLAINANT REFUSES TO PROSECUTE          0.004528\n",
      "DISTRICT ATTORNEY REFUSES TO PROSECUTE    0.004480\n",
      "NOT PROSECUTED                            0.004230\n",
      "JUVENILE CITED                            0.003795\n",
      "PROSECUTED BY OUTSIDE AGENCY              0.002852\n",
      "EXCEPTIONAL CLEARANCE                     0.001742\n",
      "JUVENILE ADMONISHED                       0.001657\n",
      "JUVENILE DIVERTED                         0.000404\n",
      "CLEARED-CONTACT JUVENILE FOR MORE INFO    0.000247\n",
      "PROSECUTED FOR LESSER OFFENSE             0.000058\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "# Count distinct for each variable:\n",
    "print \"There are a total of {:,}, values.\".format(len(data))\n",
    "\n",
    "for var, series in data.iteritems():\n",
    "    print \"There are a total of {:,} {}.\".format(len(series.value_counts()), var)\n",
    "# View All of Categories, PdDistrict, Resolution, DayOfWeek\n",
    "variables = [\"Category\", \"PdDistrict\", \"Resolution\"]\n",
    "x = data[\"Category\"].value_counts()/len(data)\n",
    "for col in variables:\n",
    "    print \"-------------------------------------------------------------------------\"\n",
    "    print \"There are a total of {:,} distinct {} values, as follows: \".format(len(data[col].value_counts()), col)\n",
    "    print data[col].value_counts()/len(data)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did more of this type of analysis but are showing only a sample for this report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model was a simple KNN model. We tried a variety of N's for neighbors and both normalized and regular data. We also looked at just including a subset of crimes for it to predict. In the end, we chose N=1, normalized data, and the top 4 crimes. One problem with KNN was that it predicted 1's and 0's, which resulted in a low score (27). For the final KNN submission, we replaced the 0's with average probability of the crime. This submission got a score of 2.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "data = data[data.Y != 90]\n",
    "stk_list = ['LARCENY/THEFT','OTHER OFFENSES','NON-CRIMINAL','ASSAULT']\n",
    "data = data[data.Category.isin(stk_list)]\n",
    "data['Dates'] = pd.to_datetime(data['Dates'])\n",
    "data['Year'] = data.Dates.dt.year\n",
    "data['Month'] = data.Dates.dt.month\n",
    "data['Day'] = data.Dates.dt.day\n",
    "data['Date'] = data.Dates.dt.date\n",
    "data['Hour'] = data.Dates.dt.hour\n",
    "data['DayOfYear'] = data.Dates.dt.dayofyear\n",
    "data['WeekDay'] = data.Dates.dt.weekday\n",
    "#\n",
    "test['Dates'] = pd.to_datetime(test['Dates'])\n",
    "test['Year'] = test.Dates.dt.year\n",
    "test['Month'] = test.Dates.dt.month\n",
    "test['Day'] = test.Dates.dt.day\n",
    "test['Date'] = test.Dates.dt.date\n",
    "test['Hour'] = test.Dates.dt.hour\n",
    "test['DayOfYear'] = test.Dates.dt.dayofyear\n",
    "test['WeekDay'] = test.Dates.dt.weekday\n",
    "def add_date_diff(df):\n",
    "    datetime_vector = pd.to_datetime(df['Dates'])\n",
    "    date_vector = datetime_vector.dt.date\n",
    "    date_diff_vector = (date_vector - date_vector.min()) / np.timedelta64(1, 'D')\n",
    "    df['DateDiff'] = date_diff_vector\n",
    "\n",
    "add_date_diff(data)\n",
    "add_date_diff(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create random dev sample so we can see how that accuracy compares to our Kaggle results\n",
    "np.random.seed(100)\n",
    "\n",
    "rows = np.random.choice(data.index, size = len(data) / 10, replace = False)\n",
    "\n",
    "dev = data.ix[rows]\n",
    "train = data.drop(rows)\n",
    "\n",
    "# Convert to Numpy Format\n",
    "train_data = np.array(train[['DateDiff','X','Y']].values)\n",
    "train_labels = np.array(train[['Category']].values.ravel())\n",
    "\n",
    "dev_data = np.array(dev[['DateDiff','X','Y']].values)\n",
    "dev_labels = np.array(dev[['Category']].values.ravel())\n",
    "\n",
    "full_data = np.array(data[['DateDiff','X','Y']].values)\n",
    "full_labels = np.array(data[['Category']].values.ravel())\n",
    "\n",
    "test_data = np.array(test[['DateDiff','X','Y']].values)\n",
    "\n",
    "# Normalize Data to Between 0-1\n",
    "#a + (x-A)*(b-a)/(B-A) \n",
    "train_normed = 0 + (np.abs(train_data) - np.abs(train_data).min(axis=0))*(1-0)/(np.abs(train_data).max(axis=0) - np.abs(train_data).min(axis=0)) \n",
    "dev_normed = 0 + (np.abs(dev_data) - np.abs(dev_data).min(axis=0))*(1-0)/(np.abs(dev_data).max(axis=0) - np.abs(dev_data).min(axis=0)) \n",
    "test_normed = 0 + (np.abs(test_data) - np.abs(train_data).min(axis=0))*(1-0)/(np.abs(train_data).max(axis=0) - np.abs(train_data).min(axis=0)) \n",
    "full_normed = 0 + (np.abs(full_data) - np.abs(train_data).min(axis=0))*(1-0)/(np.abs(train_data).max(axis=0) - np.abs(train_data).min(axis=0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use GridSearchCV to find a good number of neighbors.\n",
    "#ks = {'n_neighbors': range(1,4)}\n",
    "ks = {'n_neighbors': [1,2,3,4,5,6,7,8,9,10]}\n",
    "KNNGridSearch = GridSearchCV(KNeighborsClassifier(), ks, scoring='f1')\n",
    "KNNGridSearch.fit(train_normed, train_labels)\n",
    "#KNNmodel.fit(train_normed, train_labels)\n",
    "# Report out on the accuracies    \n",
    "print \"The scores for each k value was %s \" % (KNNGridSearch.grid_scores_)\n",
    "print \"The best k value was %s with accuracy %.4f\" % (KNNGridSearch.best_params_, KNNGridSearch.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(preds):\n",
    "    labels = [\"Id\",\n",
    "                \"ARSON\",\n",
    "                \"ASSAULT\",\n",
    "                \"BAD CHECKS\",\n",
    "                \"BRIBERY\",\n",
    "                \"BURGLARY\",\n",
    "                \"DISORDERLY CONDUCT\",\n",
    "                \"DRIVING UNDER THE INFLUENCE\",\n",
    "                \"DRUG/NARCOTIC\",\n",
    "                \"DRUNKENNESS\",\n",
    "                \"EMBEZZLEMENT\",\n",
    "                \"EXTORTION\",\n",
    "                \"FAMILY OFFENSES\",\n",
    "                \"FORGERY/COUNTERFEITING\",\n",
    "                \"FRAUD\",\n",
    "                \"GAMBLING\",\n",
    "                \"KIDNAPPING\",\n",
    "                \"LARCENY/THEFT\",\n",
    "                \"LIQUOR LAWS\",\n",
    "                \"LOITERING\",\n",
    "                \"MISSING PERSON\",\n",
    "                \"NON-CRIMINAL\",\n",
    "                \"OTHER OFFENSES\",\n",
    "                \"PORNOGRAPHY/OBSCENE MAT\",\n",
    "                \"PROSTITUTION\",\n",
    "                \"RECOVERED VEHICLE\",\n",
    "                \"ROBBERY\",\n",
    "                \"RUNAWAY\",\n",
    "                \"SECONDARY CODES\",\n",
    "                \"SEX OFFENSES FORCIBLE\",\n",
    "                \"SEX OFFENSES NON FORCIBLE\",\n",
    "                \"STOLEN PROPERTY\",\n",
    "                \"SUICIDE\",\n",
    "                \"SUSPICIOUS OCC\",\n",
    "                \"TREA\",\n",
    "                \"TRESPASS\",\n",
    "                \"VANDALISM\",\n",
    "                \"VEHICLE THEFT\",\n",
    "                \"WARRANTS\",\n",
    "                \"WEAPON LAWS\"\n",
    "              ]\n",
    "    head_str = ','.join(labels)\n",
    "\n",
    "    num_cats = len(labels)\n",
    "    \n",
    "    # Make a dummy row to append to\n",
    "    ids = np.arange(preds.shape[0])[np.newaxis].transpose()\n",
    "    \n",
    "    results = np.column_stack((ids, preds))\n",
    "\n",
    "    # Write results to csv\n",
    "    np.savetxt('sample.csv', results, fmt='%d', delimiter=',', header=head_str, comments='')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we've done this, let's run the KNN on the full train, apply to the test, then format.\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=1)\n",
    "KNNmodel.fit(full_normed, full_labels)\n",
    "dev_predict = KNNmodel.predict_proba(test_normed).astype(int)\n",
    "results = create_submission(dev_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should note that entering the other 35 categories with their average probability was doen by hand in Excel. We looked at doing it in python, but realized we wanted to pursue other models instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model was logistic regression. We tried several values of C, before settling on C=0.001. This improved our score to 2.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "clf.fit(train_data, train_labels)\n",
    "print clf.best_params_\n",
    "#print clf.grid_scores_\n",
    "res = zip(*[(f1m, f1s.std(), p['C']) \n",
    "            for p, f1m, f1s in clf.grid_scores_])\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(res[2],res[0],'-o')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(res[2],res[1],'-o')\n",
    "plt.show()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=0.001)\n",
    "model.fit(train_normed, train_labels)\n",
    "test_predict = np.array(model.predict_proba(test_normed))\n",
    "results = create_submission(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting this model, we tried averaging the KNN and LR in various ways, but that did not improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next attempt was BernoulliNB, whcih scored about the same as LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we tried GradientBoosting, which improved our score to 2.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we used a neural net, which got our best score of 2.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
