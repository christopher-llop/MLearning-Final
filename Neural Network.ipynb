{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Neural Net libraries. \n",
    "# I installed the live version of lasagne, theano, and nolearn directly from git. Follow this instructions here:\n",
    "# https://github.com/dnouri/nolearn\n",
    "from lasagne import layers\n",
    "from lasagne import nonlinearities\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/cjllop/Code/MIDS/MLearning/Final/Data/train.csv\")\n",
    "test = pd.read_csv(\"/Users/cjllop/Code/MIDS/MLearning/Final/Data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "(878049, 9)\n",
      "['Dates' 'Category' 'Descript' 'DayOfWeek' 'PdDistrict' 'Resolution'\n",
      " 'Address' 'X' 'Y']\n",
      "Test Data:\n",
      "(884262, 7)\n",
      "['Id' 'Dates' 'DayOfWeek' 'PdDistrict' 'Address' 'X' 'Y']\n"
     ]
    }
   ],
   "source": [
    "# Big Picture of Data\n",
    "print \"Train Data:\"\n",
    "print data.shape\n",
    "print data.columns.values\n",
    "print \"Test Data:\"\n",
    "print test.shape\n",
    "print test.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a column counting days since the min date in the dataset\n",
    "def add_date_diff(df):\n",
    "    datetime_vector = pd.to_datetime(df['Dates'])\n",
    "    date_vector = datetime_vector.dt.date\n",
    "    date_diff_vector = (date_vector - date_vector.min()) / np.timedelta64(1, 'D')\n",
    "    df['DateDiff'] = date_diff_vector\n",
    "    df['Year'] = datetime_vector.dt.year\n",
    "    df['Month'] = datetime_vector.dt.month\n",
    "    df['Day'] = datetime_vector.dt.day\n",
    "    df['Hour'] = datetime_vector.dt.hour\n",
    "    df['DayOfYear'] = datetime_vector.dt.dayofyear\n",
    "\n",
    "add_date_diff(data)\n",
    "add_date_diff(test)\n",
    "#print data.DateDiff.describe()\n",
    "#print test.DateDiff.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37 21 21 ..., 16 35 12]\n"
     ]
    }
   ],
   "source": [
    "# Lasagne works off of Theano instead of Numpy\n",
    "#print data.Category\n",
    "train_data = np.array(data[['X','Y','Year','Month','Day','Hour','DayOfYear']].values)\n",
    "\n",
    "panda_labels = pd.Categorical(data.Category).labels\n",
    "train_labels = np.array(panda_labels).astype(np.int32)\n",
    "print train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(790245, 10)\n",
      "(87804, 10)\n",
      "(884262, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create random dev sample so we can see how that accuracy compares to our Kaggle results\n",
    "# np.random.seed(100)\n",
    "\n",
    "# Pick 10% of rows for dev\n",
    "# rows = np.random.choice(data.index, size = len(data) / 10, replace = False)\n",
    "\n",
    "# dev = data.ix[rows]\n",
    "# train = data.drop(rows)\n",
    "\n",
    "# print train.shape\n",
    "# print dev.shape\n",
    "# print test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 509 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input        7\n",
      "  1  hidden      10\n",
      "  2  output      39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1     \u001b[36m233.39494\u001b[0m       \u001b[32m2.70657\u001b[0m     86.23266      0.19904  1.86s\n",
      "      2       \u001b[36m2.64475\u001b[0m       \u001b[32m2.70492\u001b[0m      0.97776      0.19904  1.87s\n",
      "      3       \u001b[36m2.64386\u001b[0m       \u001b[32m2.70447\u001b[0m      0.97759      0.19904  1.85s\n",
      "      4       \u001b[36m2.64356\u001b[0m       \u001b[32m2.70428\u001b[0m      0.97755      0.19904  1.94s\n",
      "      5       \u001b[36m2.64343\u001b[0m       \u001b[32m2.70418\u001b[0m      0.97753      0.19904  1.93s\n",
      "      6       \u001b[36m2.64335\u001b[0m       \u001b[32m2.70412\u001b[0m      0.97753      0.19904  1.90s\n",
      "      7       \u001b[36m2.64330\u001b[0m       \u001b[32m2.70408\u001b[0m      0.97752      0.19904  1.99s\n",
      "      8       \u001b[36m2.64327\u001b[0m       \u001b[32m2.70406\u001b[0m      0.97752      0.19904  2.22s\n",
      "      9       \u001b[36m2.64324\u001b[0m       \u001b[32m2.70404\u001b[0m      0.97752      0.19904  2.06s\n",
      "     10       \u001b[36m2.64323\u001b[0m       \u001b[32m2.70402\u001b[0m      0.97752      0.19904  2.02s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c727450>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c7273d0>,\n",
       "     custom_score=None, hidden_num_units=10, input_shape=(None, 7),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=10, more_params={},\n",
       "     objective=<function objective at 0x10c72a938>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c645a28>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x11a916560>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x11a9165f0>],\n",
       "     output_nonlinearity=<function softmax at 0x10c4fa140>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c727490>,\n",
       "     update=<function nesterov_momentum at 0x10c656758>,\n",
       "     update_learning_rate=0.02, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple net... for some reason this is currently just picking the most common class for everything\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 7),  # 3 input pixels per batch\n",
    "    hidden_num_units=10,  # number of units in hidden layer\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    output_num_units=39,  # 39 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.02,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=10,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "net1.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAESCAYAAAASQMmzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120ffcfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = np.array([i[\"train_loss\"] for i in net1.train_history_])\n",
    "valid_loss = np.array([i[\"valid_loss\"] for i in net1.train_history_])\n",
    "plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(1e-0, 1e1)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "# Looks pretty bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1513\n",
      "          1       0.00      0.00      0.00     76876\n",
      "          2       0.00      0.00      0.00       406\n",
      "          3       0.00      0.00      0.00       289\n",
      "          4       0.00      0.00      0.00     36755\n",
      "          5       0.00      0.00      0.00      4320\n",
      "          6       0.00      0.00      0.00      2268\n",
      "          7       0.00      0.00      0.00     53971\n",
      "          8       0.00      0.00      0.00      4280\n",
      "          9       0.00      0.00      0.00      1166\n",
      "         10       0.00      0.00      0.00       256\n",
      "         11       0.00      0.00      0.00       491\n",
      "         12       0.00      0.00      0.00     10609\n",
      "         13       0.00      0.00      0.00     16679\n",
      "         14       0.00      0.00      0.00       146\n",
      "         15       0.00      0.00      0.00      2341\n",
      "         16       0.20      1.00      0.33    174900\n",
      "         17       0.00      0.00      0.00      1903\n",
      "         18       0.00      0.00      0.00      1225\n",
      "         19       0.00      0.00      0.00     25989\n",
      "         20       0.00      0.00      0.00     92304\n",
      "         21       0.00      0.00      0.00    126182\n",
      "         22       0.00      0.00      0.00        22\n",
      "         23       0.00      0.00      0.00      7484\n",
      "         24       0.00      0.00      0.00      3138\n",
      "         25       0.00      0.00      0.00     23000\n",
      "         26       0.00      0.00      0.00      1946\n",
      "         27       0.00      0.00      0.00      9985\n",
      "         28       0.00      0.00      0.00      4388\n",
      "         29       0.00      0.00      0.00       148\n",
      "         30       0.00      0.00      0.00      4540\n",
      "         31       0.00      0.00      0.00       508\n",
      "         32       0.00      0.00      0.00     31414\n",
      "         33       0.00      0.00      0.00         6\n",
      "         34       0.00      0.00      0.00      7326\n",
      "         35       0.00      0.00      0.00     44725\n",
      "         36       0.00      0.00      0.00     53781\n",
      "         37       0.00      0.00      0.00     42214\n",
      "         38       0.00      0.00      0.00      8555\n",
      "\n",
      "avg / total       0.04      0.20      0.07    878049\n",
      "\n",
      "The accuracy is: 0.199191616869\n"
     ]
    }
   ],
   "source": [
    "train_pred = net1.predict(train_data)\n",
    "print(classification_report(train_labels, train_pred))\n",
    "print 'The accuracy is:', accuracy_score(train_labels, train_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 619 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input         7\n",
      "  1  dense0       10\n",
      "  2  dropout      10\n",
      "  3  dense1       10\n",
      "  4  output       39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m4.14217\u001b[0m       \u001b[32m2.70658\u001b[0m      1.53041      0.19904  2.46s\n",
      "      2       \u001b[36m2.64476\u001b[0m       \u001b[32m2.70492\u001b[0m      0.97776      0.19904  2.82s\n",
      "      3       \u001b[36m2.64386\u001b[0m       \u001b[32m2.70447\u001b[0m      0.97759      0.19904  2.76s\n",
      "      4       \u001b[36m2.64356\u001b[0m       \u001b[32m2.70428\u001b[0m      0.97755      0.19904  2.82s\n",
      "      5       \u001b[36m2.64343\u001b[0m       \u001b[32m2.70418\u001b[0m      0.97753      0.19904  2.74s\n",
      "      6       \u001b[36m2.64335\u001b[0m       \u001b[32m2.70412\u001b[0m      0.97753      0.19904  2.90s\n",
      "      7       \u001b[36m2.64330\u001b[0m       \u001b[32m2.70408\u001b[0m      0.97752      0.19904  2.99s\n",
      "      8       \u001b[36m2.64327\u001b[0m       \u001b[32m2.70406\u001b[0m      0.97752      0.19904  2.91s\n",
      "      9       \u001b[36m2.64324\u001b[0m       \u001b[32m2.70404\u001b[0m      0.97752      0.19904  2.77s\n",
      "     10       \u001b[36m2.64323\u001b[0m       \u001b[32m2.70402\u001b[0m      0.97752      0.19904  2.76s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c727450>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c7273d0>,\n",
       "     custom_score=None, dense0_num_units=10, dense1_num_units=10,\n",
       "     dropout_p=0.5, input_shape=(None, 7),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('dense0', <class 'lasagne.layers.dense.DenseLayer'>), ('dropout', <class 'lasagne.layers.noise.DropoutLayer'>), ('dense1', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=10, more_params={},\n",
       "     objective=<function objective at 0x10c72a938>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c645a28>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x1290f2d40>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x1290f2d88>],\n",
       "     output_nonlinearity=<function softmax at 0x10c4fa140>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c727490>,\n",
       "     update=<function nesterov_momentum at 0x10c656758>,\n",
       "     update_learning_rate=0.02, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tried a more complicated net with layers... still doing the same thing.\n",
    "net2 = NeuralNet(\n",
    "    layers=[  # more layers\n",
    "        ('input', layers.InputLayer),\n",
    "        ('dense0', layers.DenseLayer),\n",
    "        ('dropout', layers.DropoutLayer),\n",
    "        ('dense1', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 7),  # 3 input pixels per batch\n",
    "    dense0_num_units=10,  # number of units in hidden layer\n",
    "    dropout_p=0.5,  # Not sure what this does.....\n",
    "    dense1_num_units=10,  # number of units in hidden layer\n",
    "    output_num_units=39,  # 39 target values\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.02,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=10,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "net2.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "Old code below here\n",
    "____\n",
    "____\n",
    "____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BernoulliRBM' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-12d76fb973a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#NNmodel = BernoulliRBM()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#NNmodel.fit(train_data, train_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdev_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"The NN with normalized DateDiff, X and Y (k=1) scores: {:.6f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BernoulliRBM' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "#OLD - NOT USING Fit a basic RBM\n",
    "\n",
    "#NNmodel = BernoulliRBM()\n",
    "#NNmodel.fit(train_data, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.]\n",
      "[ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Convert to Numpy Format\n",
    "# TODO: Add more features here\n",
    "train_data = np.array(train[['DateDiff','X','Y']].values)\n",
    "train_labels = np.array(train[['Category']].values.ravel())\n",
    "\n",
    "dev_data = np.array(dev[['DateDiff','X','Y']].values)\n",
    "dev_labels = np.array(dev[['Category']].values.ravel())\n",
    "\n",
    "full_data = np.array(data[['DateDiff','X','Y']].values)\n",
    "full_labels = np.array(data[['Category']].values.ravel())\n",
    "\n",
    "test_data = np.array(test[['DateDiff','X','Y']].values)\n",
    "\n",
    "# Normalize Data to Between 0-1\n",
    "# a + (x-A)*(b-a)/(B-A) \n",
    "# TODO: Fix normalization to kick out \"bad\" x/y\n",
    "train_normed = 0 + (np.abs(train_data) - np.abs(train_data).min(axis=0))*(1-0)/(np.abs(train_data).max(axis=0) - np.abs(train_data).min(axis=0)) \n",
    "dev_normed = 0 + (np.abs(dev_data) - np.abs(dev_data).min(axis=0))*(1-0)/(np.abs(dev_data).max(axis=0) - np.abs(dev_data).min(axis=0)) \n",
    "\n",
    "print train_normed.min(axis=0)\n",
    "print train_normed.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Below this point is from KNN - here to steal bits from while I work on NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for each k value was [mean: 0.00303, std: 0.00382, params: {'n_neighbors': 1}, mean: 0.00314, std: 0.00389, params: {'n_neighbors': 2}, mean: 0.00300, std: 0.00380, params: {'n_neighbors': 3}, mean: 0.00302, std: 0.00378, params: {'n_neighbors': 4}, mean: 0.00299, std: 0.00371, params: {'n_neighbors': 5}, mean: 0.00300, std: 0.00373, params: {'n_neighbors': 6}, mean: 0.00297, std: 0.00372, params: {'n_neighbors': 7}, mean: 0.00297, std: 0.00371, params: {'n_neighbors': 8}, mean: 0.00295, std: 0.00369, params: {'n_neighbors': 9}, mean: 0.00295, std: 0.00368, params: {'n_neighbors': 10}] \n",
      "The best k value was {'n_neighbors': 2} with accuracy 0.0031\n"
     ]
    }
   ],
   "source": [
    "# Use GridSearchCV to find a good number of neighbors.\n",
    "#ks = {'n_neighbors': range(1,4)}\n",
    "ks = {'n_neighbors': [1,2,3,4,5,6,7,8,9,10]}\n",
    "KNNGridSearch = GridSearchCV(KNeighborsClassifier(), ks, scoring='f1_weighted')\n",
    "KNNGridSearch.fit(train_data, train_labels)\n",
    "\n",
    "# Report out on the accuracies    \n",
    "print \"The scores for each k value was %s \" % (KNNGridSearch.grid_scores_)\n",
    "print \"The best k value was %s with accuracy %.4f\" % (KNNGridSearch.best_params_, KNNGridSearch.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KNN with DateDiff, X and Y (k=2) scores: 0.220072\n"
     ]
    }
   ],
   "source": [
    "# Try k = 2\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=1)\n",
    "KNNmodel.fit(train_data, train_labels)\n",
    "dev_predict = KNNmodel.predict(dev_data)\n",
    "print \"The KNN with DateDiff, X and Y (k=2) scores: {:.6f}\".format(metrics.f1_score(dev_labels, dev_predict, average='weighted'))\n",
    "\n",
    "\n",
    "# Tried a few tests (including the above). So far k=1 seems best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we've sorted out a naive alg to run. Let's train on all train, then predict on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(preds):\n",
    "    labels = [\"Id\",\n",
    "                \"ARSON\",\n",
    "                \"ASSAULT\",\n",
    "                \"BAD CHECKS\",\n",
    "                \"BRIBERY\",\n",
    "                \"BURGLARY\",\n",
    "                \"DISORDERLY CONDUCT\",\n",
    "                \"DRIVING UNDER THE INFLUENCE\",\n",
    "                \"DRUG/NARCOTIC\",\n",
    "                \"DRUNKENNESS\",\n",
    "                \"EMBEZZLEMENT\",\n",
    "                \"EXTORTION\",\n",
    "                \"FAMILY OFFENSES\",\n",
    "                \"FORGERY/COUNTERFEITING\",\n",
    "                \"FRAUD\",\n",
    "                \"GAMBLING\",\n",
    "                \"KIDNAPPING\",\n",
    "                \"LARCENY/THEFT\",\n",
    "                \"LIQUOR LAWS\",\n",
    "                \"LOITERING\",\n",
    "                \"MISSING PERSON\",\n",
    "                \"NON-CRIMINAL\",\n",
    "                \"OTHER OFFENSES\",\n",
    "                \"PORNOGRAPHY/OBSCENE MAT\",\n",
    "                \"PROSTITUTION\",\n",
    "                \"RECOVERED VEHICLE\",\n",
    "                \"ROBBERY\",\n",
    "                \"RUNAWAY\",\n",
    "                \"SECONDARY CODES\",\n",
    "                \"SEX OFFENSES FORCIBLE\",\n",
    "                \"SEX OFFENSES NON FORCIBLE\",\n",
    "                \"STOLEN PROPERTY\",\n",
    "                \"SUICIDE\",\n",
    "                \"SUSPICIOUS OCC\",\n",
    "                \"TREA\",\n",
    "                \"TRESPASS\",\n",
    "                \"VANDALISM\",\n",
    "                \"VEHICLE THEFT\",\n",
    "                \"WARRANTS\",\n",
    "                \"WEAPON LAWS\"\n",
    "              ]\n",
    "    head_str = ','.join(labels)\n",
    "\n",
    "    num_cats = len(labels)\n",
    "    \n",
    "    # Make a dummy row to append to\n",
    "    ids = np.arange(preds.shape[0])[np.newaxis].transpose()\n",
    "    \n",
    "    results = np.column_stack((ids, preds))\n",
    "\n",
    "    # Write results to csv\n",
    "    np.savetxt('sample.csv', results, fmt='%d', delimiter=',', header=head_str, comments='')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we've done this, let's run the KNN on the full train, apply to the test, then format.\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=1)\n",
    "KNNmodel.fit(full_data, full_labels)\n",
    "dev_predict = KNNmodel.predict_proba(test_data).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = create_submission(dev_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884262, 40)\n"
     ]
    }
   ],
   "source": [
    "print results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
