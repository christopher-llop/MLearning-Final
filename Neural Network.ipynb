{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-207dce2cf9bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# I installed the live version of lasagne, theano, and nolearn directly from git. Follow this instructions here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# https://github.com/dnouri/nolearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnonlinearities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnesterov_momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/lasagne/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     raise ImportError(\"\"\"Could not import Theano.\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/theano/__init__.pyc\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mtheano_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigdefaults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Version information.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/theano/configdefaults.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;31m# Test whether or not g++ is present: disable C code if it is not.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_subprocess_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'g++'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/theano/misc/windows.pyc\u001b[0m in \u001b[0;36mcall_subprocess_Popen\u001b[0;34m(command, **params)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_eintr_retry_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mECHILD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m_eintr_retry_call\u001b[0;34m(func, *args)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Neural Net libraries. \n",
    "# I installed the live version of lasagne, theano, and nolearn directly from git. Follow this instructions here:\n",
    "# https://github.com/dnouri/nolearn\n",
    "from lasagne import layers\n",
    "from lasagne import nonlinearities\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "# Function to print all pandas rows\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    pd.set_option('display.max_columns', len(x.columns))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/cjllop/Code/MIDS/MLearning/Final/Data/train.csv\")\n",
    "test = pd.read_csv(\"/Users/cjllop/Code/MIDS/MLearning/Final/Data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Big Picture of Data\n",
    "print \"Train Data:\"\n",
    "print data.shape\n",
    "print data.columns.values\n",
    "print \"Test Data:\"\n",
    "print test.shape\n",
    "print test.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract new features here because it's easier in Pandas than NumPy\n",
    "def build_features(data):\n",
    "    data['DateTime'] = pd.to_datetime(data['Dates'])\n",
    "    date_vector = data['DateTime'].dt.date\n",
    "    data['DateDiff'] = (date_vector - date_vector.min()) / np.timedelta64(1, 'D')\n",
    "    data['Year'] = pd.DatetimeIndex(data['DateTime']).year\n",
    "    data['Month'] = pd.DatetimeIndex(data['DateTime']).month\n",
    "    data['Day'] = pd.DatetimeIndex(data['DateTime']).day\n",
    "    data['Hour'] = pd.DatetimeIndex(data['DateTime']).hour\n",
    "    data['SecondsDelta'] = (data.DateTime - pd.Timestamp('2013-01-01')) / np.timedelta64(1,'s')\n",
    "    data['Weekend'] = (data.DayOfWeek == \"Saturday\") | (data.DayOfWeek == \"Sunday\")\n",
    "    data['XR'] = data['X'].round(decimals=3).apply(str)\n",
    "    data['YR'] = data['Y'].round(decimals=3).apply(str)\n",
    "    data['XR4'] = data['X'].round(decimals=4).apply(str)\n",
    "    data['YR4'] = data['Y'].round(decimals=4).apply(str)\n",
    "    years = pd.get_dummies(data.Year)\n",
    "    years.columns = ['2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "    months = pd.get_dummies(data.Month)\n",
    "    months.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    days = pd.get_dummies(data.Day)\n",
    "    days.columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "    daysofweek = pd.get_dummies(data.DayOfWeek)\n",
    "    hours = pd.get_dummies(data.Hour)\n",
    "    hours.columns = ['12AM', '1AM', '2AM', '3AM', '4AM', '5AM',\n",
    "                     '6AM', '7AM', '8AM', '9AM', '10AM', '11AM',\n",
    "                     '12PM', '1PM', '2PM', '3PM', '4PM', '5PM',\n",
    "                     '6PM', '7PM', '8PM', '9PM', '10PM', '11PM']\n",
    "    districts = pd.get_dummies(data.PdDistrict)\n",
    "    new_data = pd.concat([data, years, months, days, daysofweek, hours, districts], axis=1)\n",
    "    return new_data\n",
    "\n",
    "data = build_features(data)\n",
    "data_XRs = pd.get_dummies(data.XR)\n",
    "data_YRs = pd.get_dummies(data.YR)    \n",
    "data_XR4s = pd.get_dummies(data.XR4)\n",
    "data_YR4s = pd.get_dummies(data.YR4)    \n",
    "test = build_features(test)\n",
    "test_XRs = pd.get_dummies(test.XR)\n",
    "test_YRs = pd.get_dummies(test.YR)    \n",
    "test_XR4s = pd.get_dummies(test.XR4)\n",
    "test_YR4s = pd.get_dummies(test.YR4)    \n",
    "\n",
    "#print data.columns.values\n",
    "print test_XR4s.columns.values\n",
    "print test_YR4s.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate labels\n",
    "train_labels = data.Category\n",
    "\n",
    "# Create integer labels\n",
    "panda_labels = pd.Categorical(data.Category).codes\n",
    "train_labels_int = np.array(panda_labels).astype(np.int32)\n",
    "\n",
    "# Drop Category, Descript and Resolution columns since we cannot use them to predict. Drop non-numerics too for NN.\n",
    "train_data = data.drop(['Category', 'Descript', 'Resolution', 'DateTime', 'Dates', 'PdDistrict', 'Address', 'DayOfWeek'], axis=1)\n",
    "train_data.Weekend = train_data.Weekend * 1\n",
    "train_names = train_data.columns.values.tolist()\n",
    "\n",
    "test_data = test.drop(['DateTime', 'Dates', 'PdDistrict', 'Address', 'DayOfWeek'], axis=1)\n",
    "test_data.Weekend = test_data.Weekend * 1\n",
    "test_names = test_data.columns.values.tolist()\n",
    "\n",
    "\n",
    "#print_full(train_data.head(5))\n",
    "print_full(test_data.head(5))\n",
    "\n",
    "#print_full(pd.DataFrame(train_data.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO \n",
    "#data_address_dummies = pd.get_dummies(data.Address,sparse=True)\n",
    "#test_address_dummies = pd.get_dummies(test.Address,sparse=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO \n",
    "#print pd.concat([data, pd.get_dummies(data.PdDistrict, prefix=\"PdDistrict\")], axis=1)\n",
    "# Let's create dummy variables for any address with over 100 events.\n",
    "address_counts = data[\"Address\"].value_counts()\n",
    "address_list = pd.Series(address_counts[address_counts > 100].index).to_frame(\"Address\")\n",
    "#print len(address_counts)\n",
    "#print len(address_counts[address_counts > 100])\n",
    "#address_list.columns.values = [\"Address\"]\n",
    "#print pd.DataFrame(address_list).columns.values\n",
    "#print data.columns.values\n",
    "#print address_list\n",
    "top_address = pd.merge(data, address_list, how='inner', on=['Address'])\n",
    "#top_address['temp'] = 1\n",
    "#bottom_address = pd.merge(data, top_address, how='left', on=['Address'])\n",
    "print data.shape\n",
    "print result.shape\n",
    "#print bottom_address.shape\n",
    "\n",
    "#address_counts[address_counts > 100].index.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lasagne works off of Theano instead of Numpy\n",
    "#print data.Category\n",
    "#train_data = np.array(data[['X','Y','Year','Month','Day','Hour','DayOfYear']].values)\n",
    "#train_data = np.array(data_features)\n",
    "\n",
    "#panda_labels = pd.Categorical(data.Category).labels\n",
    "#train_labels = np.array(panda_labels).astype(np.int32)\n",
    "#print train_labels\n",
    "#print train_data.groupby(level=0).first()\n",
    "#print train_data.index.get_duplicates()\n",
    "#print train_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(790245, 10)\n",
      "(87804, 10)\n",
      "(884262, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create random dev sample so we can see how that accuracy compares to our Kaggle results\n",
    "# np.random.seed(100)\n",
    "\n",
    "# Pick 10% of rows for dev\n",
    "# rows = np.random.choice(data.index, size = len(data) / 10, replace = False)\n",
    "\n",
    "# dev = data.ix[rows]\n",
    "# train = data.drop(rows)\n",
    "\n",
    "# print train.shape\n",
    "# print dev.shape\n",
    "# print test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features = [\n",
    " 'X', 'Y', 'DateDiff', 'Year', 'Month', 'Day', 'Hour',\n",
    " 'SecondsDelta', 'Weekend', '2003', '2004', '2005', '2006', '2007', '2008', '2009',\n",
    " '2010', '2011', '2012', '2013', '2014', '2015', 'Jan', 'Feb', 'Mar', 'Apr', 'May',\n",
    " 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    " '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',\n",
    " '24', '25', '26', '27', '28', '29', '30', '31', 'Friday', 'Monday', 'Saturday',\n",
    " 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM',\n",
    " '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM',\n",
    " '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL',\n",
    " 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL',\n",
    " 'TENDERLOIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "#features = ['X', 'Y'] #???? | ???? | 2.69680 | 0.1871\n",
    "#features = ['X', 'Y', 'DateDiff'] #2.73877 | 2.69913 | 2.69680 | 0.199\n",
    "#features = ['X', 'Y', 'DateDiff', 'Year', 'Month', 'Day', 'Hour', 'Weekend'] #2.73866 | 2.69914 || 0.199\n",
    "#features = ['X', 'Y', 'Year', 'Month', 'Day', 'Hour', 'Weekend'] #2.73870\n",
    "#features = ['Year', 'Month', 'Day', 'Hour', 'Weekend'] #2.73867\n",
    "#features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',] # 2.70496\n",
    "#2.64560 | 2.62009 | 0.174%\n",
    "#features = ['2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "#2.71693|||0.20055\n",
    "#[(200,10) = 0.231704608741]\n",
    "#[(500,20) = 0.240513912094]\n",
    "#features = ['2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', 'Jan', 'Feb', 'Mar', 'Apr', 'May',  'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',  '24', '25', '26', '27', '28', '29', '30', '31', 'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM',  '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "#features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "features = ['Jan','Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "\n",
    "\n",
    "#np_train_data = np.array(train_data[features])\n",
    "#np_train_data = np.array(pd.concat([data_XRs, data_YRs], axis=1))\n",
    "#np_train_data = np.array(pd.concat([train_data[features], data_XRs, data_YRs], axis=1))\n",
    "# Need to drop any \"test\" coordinate features that are not in \"train\". We accept this as a limitation.\n",
    "#np_test_data = np.array(pd.concat([test_data[features], test_XRs[list(data_XRs)], test_YRs[list(data_YRs)]], axis=1))\n",
    "\n",
    "#np_train_data = np.array(pd.concat([train_data[features], (data.Year < 2006) * 1, (data.Year < 2008) * 1, (data.Year < 2010) * 1, data_XRs, data_YRs], axis=1))\n",
    "np_train_data = np.array(pd.concat([train_data[features], (data.Year < 2006) * 1, (data.Year < 2008) * 1, (data.Year < 2010) * 1, data_XR4s, data_YR4s], axis=1))\n",
    "\n",
    "\n",
    "print np_train_data.shape\n",
    "print np_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 300)\n",
      "(878049,)\n",
      "# Neural Network with 170039 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input      300\n",
      "  1  hidden     500\n",
      "  2  output      39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.62524\u001b[0m       \u001b[32m2.62010\u001b[0m      1.00196      0.22793  31.09s\n",
      "      2       \u001b[36m2.51991\u001b[0m       \u001b[32m2.59395\u001b[0m      0.97146      0.23027  31.75s\n",
      "      3       \u001b[36m2.49565\u001b[0m       \u001b[32m2.58080\u001b[0m      0.96701      0.23249  30.31s\n",
      "      4       \u001b[36m2.48162\u001b[0m       \u001b[32m2.57397\u001b[0m      0.96412      0.23394  30.69s\n",
      "      5       \u001b[36m2.47219\u001b[0m       \u001b[32m2.57061\u001b[0m      0.96171      0.23578  29.10s\n",
      "      6       \u001b[36m2.46487\u001b[0m       \u001b[32m2.56895\u001b[0m      0.95949      0.23725  29.60s\n",
      "      7       \u001b[36m2.45866\u001b[0m       \u001b[32m2.56775\u001b[0m      0.95752      0.23915  30.70s\n",
      "      8       \u001b[36m2.45311\u001b[0m       \u001b[32m2.56674\u001b[0m      0.95573      0.24057  30.76s\n",
      "      9       \u001b[36m2.44801\u001b[0m       \u001b[32m2.56581\u001b[0m      0.95409      0.24198  29.63s\n",
      "     10       \u001b[36m2.44327\u001b[0m       \u001b[32m2.56441\u001b[0m      0.95276      0.24341  29.81s\n",
      "     11       \u001b[36m2.43882\u001b[0m       \u001b[32m2.56276\u001b[0m      0.95164      0.24499  29.74s\n",
      "     12       \u001b[36m2.43462\u001b[0m       \u001b[32m2.56081\u001b[0m      0.95072      0.24621  29.40s\n",
      "     13       \u001b[36m2.43065\u001b[0m       \u001b[32m2.55863\u001b[0m      0.94998      0.24718  29.61s\n",
      "     14       \u001b[36m2.42685\u001b[0m       \u001b[32m2.55644\u001b[0m      0.94931      0.24785  29.53s\n",
      "     15       \u001b[36m2.42323\u001b[0m       \u001b[32m2.55420\u001b[0m      0.94873      0.24920  31.53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc1d0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc150>,\n",
       "     custom_score=None, hidden_num_units=500, input_shape=(None, 300),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x10c3c5c80>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c1e2c80>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x120c6ae18>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x132c39488>],\n",
       "     output_nonlinearity=<function softmax at 0x10c09c398>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c3cc210>,\n",
       "     update=<function nesterov_momentum at 0x10c1f59b0>,\n",
       "     update_learning_rate=0.002, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "# The accuracy is: 0.283077595897\n",
    "# Should run again stopping early @ 77 for better results\n",
    "num_features = np_train_data.shape[1]\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, num_features),  # 3 input pixels per batch\n",
    "    hidden_num_units=500,  # number of units in hidden layer\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    output_num_units=39,  # 39 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.002,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "print np_train_data.shape\n",
    "print train_labels.shape\n",
    "#print len(train_data.columns)\n",
    "net1.fit(np_train_data, train_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAESCAYAAAAMifkAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF9tJREFUeJzt3XvQHXV9x/HPJwnBQAKIIgqCQQGVolxaweItFS94GbBa\nUFRGodbRwarV8cagSexM7dix1alSnKooKCgoozjFgqAPMEUBBZRrBRouEQ2XEElAQy7f/rH75Hey\nnD17nufZfc7Z7Ps1s3P27O4553e+mZzvs7/v77friBAAAIPMGXUDAADjj2QBAKhEsgAAVCJZAAAq\nkSwAAJVIFgCASiQLAEAlkgUAoNJYJQvb+9j+iu3zRt0WAEAyVskiIlZExLtG3Q4AwNYaTxa2v2Z7\nle0bCtuPsn2r7dtsf6zpdgAApm82zizOkHRU7wbbcyV9Md9+gKTjbT93FtoCAJiGxpNFRFwh6aHC\n5sMk3R4Rd0bEBknflnSM7V1tny7pYM42AGB8zBvR5+4p6Z6e5yslHR4RqyW9ZzRNAgCUGVWymNF1\n0W1zXXUAmIaI8HReN6pk8VtJe/U830vZ2cXQpvuFtzW2l0XEslG3YxwQi4RYJMQimckf2qMaOvsL\nSfvZXmx7vqQ3S7pgRG1pu8WjbsAYWTzqBoyRxaNuwBhZPOoGbAtmY+jsOZKulLS/7XtsnxgRGyW9\nT9JFkm6W9J2IuKXptgAApsdtvK2q7aAbKmN7SURMjLod44BYJMQiIRbJTH47SRYA0BEz+e0cVYEb\nNeGvpoRYJF2IBaMiB6v7D2qSBYDWGuYHsQuJs6iJREo3FIBW4negXFlsZhKzsbrqLABgPLU2Wdhe\nZnvJqNsxasQgIRYJsUjaGAvb/2H71Brfb4ntZTN5j9bWLJiRCWBc2b5T0kkR8ZPpvD4i3ltne/Ka\nzYTtpdN9D2oWAFppnH8HbK+Q9K6IuLTPvnn5xOQmP5+aBQCMM9tnSdpb0g9tr7X9EdubbZ9k+y5J\nl+THnWf7d7bX2L7M9gE97/F12/+Yry+xvdL2h/Ibyd1r+52z/b1IFi3Xxv7YphCLhFgksx2LiDhB\n0t2SXh8RiySdm+96qaTnSHp1/vy/JO0raTdJ10r6Vu/baOurc+8uaSdJe0j6W0lfsr1zU9+hn9bW\nLACgjN37QxvyDDurIjSTd5h87bKI+GN6z/j6lgPs5ZI+YHtRRKwtvE6SNkj6dERslvQj2+skPVvS\n1TNo15RwZtFyXZtsNAixSIjFWNpywzfbc2z/s+3bbf9B0op815NLXvtgnigmPSppYUPt7ItkAQD1\n6zdyqHfb2yQdLenIiNhZ0j75dpccP3Iki5ajbzohFknXYxEhTy6S/6r3+XSWaTRhlaRnDdi/UNJ6\nSatt7yjpnwr7Lc2o66t2JAsAqN9nJJ1qe7WkN+nxZwlnSrpL2V1Db5T0s8IxxQL3yM8ymGcBoJX4\nHSjXxDyL1o6GyqeuT1DIA4DB8m7JJTN6D84s2q2Ll18uQyySLsRi2N+BLsSiiBncAICR4MwCQCvx\nO1COMwsAwEiQLFqu6+PpexGLhFgkxKIeJAsAQCVqFgBaid+BctQsAGAbld+3ovdigzfafukwx84G\nkkXL0R+bEIuEWCRtjUVEHBgRl4+6HZNIFgCASiSLluvazNRBiEVCLJLZjoXtj9k+r7DtC/nyTts3\n237Y9h223z3gfe60fWS+viC/1epq2zdJekHDX+NxWnttKAAYU+dI+pTthRGxzvZcScdKeoOymxu9\nLiJW5PWIH9m+JiKu6/M+vVeeXarsnhfPVHZ58//WLF+JtrXJggsJZrp43ZsyxCLpeiy83LX+kMbS\n4UcQRcTdtq+V9NeSzpL0ckmPRsTVheMut32xpJdI6pcseh0r6b0RsUbSGttfkPSpYdtUx4UEW9sN\nFRHLuvyfAcBYO1vS8fn6WyV9S5Jsv8b2z20/aPshSa+V9KQh3m8P9dyWVdLdU2lMRExExLKpvKao\ntckCGRJmQiwSYjFy35W0xPaeyrqfzra9vaTvSfqspKdExBMlXajh7oj3O0l79zzfu+zAprS2GwoA\nykyl26iRz4+43/aEpK9L+r+I+F/biyTNl/SApM22XyPpVZJuGOItz5X0CdtXKatZ/H0jDR+AM4uW\na+sY8iYQi4RYJCOMxdmSjswfFRFrJb1f2Q//amXdVD8ovKas1rJc2W1YVygrbp854NhGcLmPlut6\nIbMXsUi6EAtuflSuict9kCwAtBK/A+W4NhQAYCRIFi1H33RCLBJikRCLepAsAACVqFkAaCV+B8pR\nswAAjATJouXoj02IRUIsEmJRD2ZwA2gte7gLBtr0Vs0UNQsA6IiZ/Ha29syCS5QDwHDquEQ5ZxYt\n18VLGZQhFgmxSIhFwmgoAECjOLMAgI7gzAIA0CiSRcsxhjwhFgmxSIhFPUgWAIBK1CwAoCOoWQAA\nGkWyaDn6YxNikRCLhFjUg2QBAKhEzQIAOoKaBQCgUSSLlqM/NiEWCbFIiEU9SBYAgErULACgI6hZ\nAAAaRbJoOfpjE2KREIuEWNSDO+UBwDaOO+UBAIZGzQIA0CiSRcvRH5sQi4RYJMSiHiQLAEAlahYA\n0BHULAAAjSJZtBz9sQmxSIhFQizqQbIAAFSiZgEAHUHNAgDQKJJFy9EfmxCLhFgkxKIeJAsAQCVq\nFgDQEdQsAACNIlm0HP2xCbFIiEVCLOpBsgAAVKJmAQAdQc0CANAokkXL0R+bEIuEWCTEoh4kCwBA\npdbWLCQtlzQRERMjbg4AjLX87GqJpKXTrVm0NllQ4AaAqaHA3WH0xybEIiEWCbGoB8kCAFCJbigA\n6Ai6oQAAjSJZtBz9sQmxSIhFQizqQbIAAFSiZgEAHUHNAgDQKJJFy9EfmxCLhFgkxKIeJAsAQCVq\nFgDQEdQsAACNIlm0HP2xCbFIiEVCLOpRmSxsf9D2zs581fZ1tl89G40DAIyHypqF7V9HxPPzBPEe\nSZ+UdFZEHDIbDSxpEzULAJiipmsWk2/8OmVJ4sbpfBAAoL2GSRa/tH2xpNdKusj2TpI2N9ssDIv+\n2IRYJMQiIRb1mDfEMSdJOkTSHRHxiO0nSTqx2WYBAMbJMDWLF0n6VUSss32CpEMlfT4i7pqNBpa0\niZoFAExR0zWL0yU9YvsgSR+SdLukM6fzYQCAdhomWWyM7PTjDZK+FBFfkrSo2WZhWPTHJsQiIRYJ\nsajHMDWLtbZPkfR2SS+xPVfSds02CwAwToapWTxN0lslXR0RV9jeW9KSiBhZVxQ1CwCYupn8dg51\nIUHbT5X0AkmhLGncN50PqwvJAgCmrtECt+3jJF0l6VhJx0m62vax0/kw1I/+2IRYJMQiIRb1GKZm\ncaqkF0yeTdjeTdKlks5rsmEAgPExTLKwpPt7nj+odAmQkbG9TNJEREyMuCkj1fXv34tYJMQiIRZb\nzq6WzOg9hihw/4ukgySdrSxJvFnSryPiozP54JmgZgEAU9f0pLyPSvqysoTxPElfHmWiwNboj02I\nRUIsEmJRj8puqHxC3vfyBQDQQaXdULbXKRsq209ExE6NtaoC3VAAMHUz+e0sPbOIiIXTbxIAYFvC\nPbhbjv7YhFgkxCIhFvUgWQAAKg11uY9xQ80CAKau6aGzAICOI1m0HP2xCbFIiEVCLOrR2mThj+/K\nDZgAYJa0tmahpd4sx1WSLpd0s6TfSLpN0upY2sIvBQANa/x+FuPGdmhZ6e71klblywOS1kj6Q76s\nzZd1+fJIz/KopD/2PP5J0mMkHgDbCpJFc0JZ0phMHusLS3HbY4X14rKh5HFyfdhl45bHz+mF+rB+\nKmlD1xOb7SVcYTRDLBJikTQyg3vsffZ+6RmXSXtf8ZAOOutqLVj9VFn7Stqxxk+xpAX5Mp7emFa9\n3JuVkknvMrltU2H7pj7bN/UsG0vWp7Nszpfe58XHzX2eF/cVl7T/MD3fy93v+Ch5HiXHFPf3e4wh\nt/ddup7Y0T7tPbNQPCpph57Nd0i6ULvc+UsdeM4qHfG5R7TDgztJ2iVfdpa0SNLC/HHHnmWHwjKZ\nINqbTNEW/ZKJStaL2/odpz77hzmu2J6q44qvGWbfdN9jJop/RZf9VT3ouLL1mR7nkuNcOG7Q+/U7\nvvh4VyyN/aWudkMp3qTBV8LdKGmFpHvyZaWyOsZ9+fKApNWSHozQn/p+znLPk7S9pCfky4L8eb9l\nfp/HyfXtCuvb9ezvfb5dYendNm/A+uQCAEV3xdJYLHW0GypC59t6paSTJb1Sj+9+midpv3wZyNYf\nlRXCH9JWBfFYI+nhnmVtYXlAqVi+TtL6iMb+Qippe9Yf6+W2su88VymZzOtZn9uzr3hccXvvsWXr\ncwrHDlrmDFif07PNPfuK68Xj5hTeY65u1S56jtb2OW5O4TUu2ddvvez5VNaLS/NWSNpnVj5p/BGL\nWrQ2WUhShC6RdImt7SW9WNIrJB2YL4un8FaT3U5Pm2GTNtuPG2XVO9pq8rF35FVxFNbkY9mSjdIq\nJKW8D3yyAN5JbSpk5sm9LJH0Wy/rbujfZXGhXqSTdWXlcYVm9VmvSnDD7pvue8zcZTpc++jnPVtK\nb70w4HlV1910j4uS44btMiw7vt/rZ6S13VBVp1K2Fkl6hqS98mVPSbtJeoqk3SXtKulJ+eN2jTa4\nfqGUOIqPZcv6kudVI7zKRnutj9DGxr8pgNp0smZR14UEbVlZF9Yukp6oVAyfXHbKl8kCee+yUFsX\nzOfX0aYW2ayUQIrDhouPxfXi0ruvOKS433rZvg391iO0qakgAG1BshgTtrbT1qOsekdbTa4vUBp1\nNfl8QWF9Qc9xvc8ni+w93YcTkpY0+r3aY0IDYtHbTVdMJlNdNg6xvd968XXF7b2PxWHP/bZtkLSp\nX52sTV1yTSMWSScL3OMoQhuUFcjXNPk5tuZpS+JYtkSauF5bj9YatF58nFzfvrA++Xy+ykeAjV3C\nHsBKI9C2KfaWeTA9ieXiObYe3Xrb4+bZ9EtCVccU5+RUHTNoPs+w+8rm+/Rdn+1BJl3BmQWmLU9a\nvcmk3/DhqmHEVfuKw42Lz8uGIReHIrf2opmYss2a2gTTYSefTnffdCawTnVfvwmvk8ufInSLRDcU\nUMnWXD1+HktxLst8bT2HZdBSPG7Q83kDjikOc+53bHE4dO8jSRBVVkZoL4luqE6jPzYZFIu8wL1J\n6j8Bs63sLXNHCknliBdLV16jrefS9CafuYXtZXNu+m2fV3Fc1b5BxxXn8wya69PvsU/ynFDH63q1\nDO4gWQAtFrHlelZbza+xf7Y6QveMplWjk49uLCSUk18q3XRVz/ZBE06Ly6CJqoOWYY+rmsQ61cmu\n/V577wzDKoluKADoDO7BDQBoFMmi5bi/cEIsEmKREIt6kCwAAJWoWQBAR1CzAAA0imTRcvTHJsQi\nIRYJsagHyQIAUImaBQB0BDULAECjSBYtR39sQiwSYpEQi3qQLAAAlVpbs5C0XNIEV1wFgMHys6sl\nkpZyPwsAwEAUuDuM/tiEWCTEIiEW9SBZAAAq0Q0FAB1BNxQAoFEki5ajPzYhFgmxSIhFPUgWAIBK\n1CwAoCOoWQAAGkWyaDn6YxNikRCLhFjUg2QBAKhEzQIAOoKaBQCgUSSLlqM/NiEWCbFIiEU9SBYA\ngErULACgI6hZAAAaRbJoOfpjE2KREIuEWNSDZAEAqETNAgA6gpoFAKBRJIuWoz82IRYJsUiIRT1I\nFgCAStQsAKAjqFkAABpFsmg5+mMTYpEQi4RY1INkAQCoRM0CADqCmgUAoFEki5ajPzYhFgmxSIhF\nPUgWAIBK1CwAoCOoWQAAGkWyaDn6YxNikRCLhFjUg2QBAKhEzQIAOoKaBQCgUSSLlqM/NiEWCbFI\niEU9SBYAgErULACgI6hZAAAaRbJoOfpjE2KREIuEWNSDZAEAqETNAgA6gpoFAKBRJIuWoz82IRYJ\nsUiIRT1IFgCAStQsAKAjqFkAABpFsmg5+mMTYpEQi4RY1INkAQCoRM0CADqCmgUAoFEki5ajPzYh\nFgmxSIhFPUgWAIBK1CwAoCOoWQAAGkWyaDn6YxNikRCLhFjUg2QBAKhEzQIAOmImv53z6m7MTNje\nUdJpktZLmoiIs0fcJACAxq8b6o2Szo2Id0s6etSNaQP6YxNikRCLhFjUo/FkYftrtlfZvqGw/Sjb\nt9q+zfbH8s17SronX9/UdNu2EQePugFjhFgkxCIhFjWYjTOLMyQd1bvB9lxJX8y3HyDpeNvPlbRS\n0l6z2LZtwS6jbsAYIRYJsUiIRQ0a/0GOiCskPVTYfJik2yPizojYIOnbko6RdL6kN9k+TdIFTbcN\nADCcURW4e7ubpOyM4vCIeFTSSaNpUmstHnUDxsjiUTdgjCwedQPGyOJRN2BbMKpkMePxurbbN+a3\nIbbfMeo2jAtikRCLhFjM3KiSxW+VahPK11cO+2LmWADA7BpVEfkXkvazvdj2fElvFjUKABhbszF0\n9hxJV0ra3/Y9tk+MiI2S3ifpIkk3S/pORNzSdFsAANMzG6Ohjo+IPSJi+4jYKyLOyLf/KCKeHRH7\nRsRnhnmvkrkZnWB7L9s/tX2T7Rttvz/fvqvtH9v+je2LbXdmmKDtubavs/3D/HknY2F7F9vftX2L\n7ZttH97hWHwi/z9yg+2zbW/flVj0m9M26Lvnsbot/019VdX7t2Yuw4C5GV2xQdI/RMSfSXqhpJPz\n7/9xST+OiP0lXZo/74oPKDsznRzs0NVYfEHShRHxXEnPl3SrOhgL24sl/Z2kQyPieZLmSnqLuhOL\nx81pU8l3t32Asu7/A/LXnGZ7YD5oTbJQ+dyMToiI30fE9fn6Okm3KBuCfLSkb+SHfUPSG0bTwtll\n++mSXivpK5ImBzx0Lha2d5b0koj4miRFxMaI+IM6GAtJDyv7o2oH2/Mk7SDpXnUkFiVz2sq++zGS\nzomIDRFxp6Tblf3GlmpTsug3N2PPEbVlpPK/oA6RdJWk3SNiVb5rlaTdR9Ss2fZvkj4iaXPPti7G\nYh9J99s+w/a1tv8zvyBn52IREaslfU7S3cqSxJqI+LE6GIseZd99D209ArXy97RNyYJ5FZJsL5T0\nPUkfiIi1vfsiu978Nh8n26+XdF9EXKd0VrGVrsRC2fD3QyWdFhGHSnpEhW6WrsTC9rMkfVDZJLw9\nJC20/fbeY7oSi36G+O4D49KmZDGjuRnbAtvbKUsUZ0XE9/PNq2w/Nd//NEn3jap9s+gISUfbXiHp\nHEkvt32WuhmLlZJWRsQ1+fPvKksev+9gLP5C0pUR8WA+4vJ8SX+pbsZiUtn/ieLv6dPzbaXalCw6\nPTfDtiV9VdLNEfH5nl0XSJqcnfoOSd8vvnZbExGn5CPr9lFWwPxJRJygbsbi95Lusb1/vukVkm6S\n9EN1LBbKCvsvtL0g///yCmUDILoYi0ll/ycukPQW2/Nt7yNpP0lXD3qjVt0pz/ZrJH1e2SiHrw47\n5HZbYPvFki6X9Gul08VPKPsHPlfS3pLulHRcRKwZRRtHwfbLJH04Io62vas6GAvbBykr9M+XdIek\nE5X9H+liLD6q7Edxs6RrJb1L0iJ1IBb5nLaXSXqysvrEpyT9QCXf3fYpyq7Ft1FZt/ZFA9+/TckC\nADAabeqGAgCMCMkCAFCJZAEAqESyAABUIlkAACqRLAAAlUgWwCyzvWTysupAW5AsAACVSBZACdtv\nt31VfoOl0/ObLa2z/a/5Dagusf3k/NiDbf/c9q9snz95kxnb++bHXW/7l7afqWwG/kLb5+U3LPrm\nKL8nMAySBdBHfmOp4yQdERGHSNok6W3K7pFwTUQcKOkySUvzl5wp6SMRcZCkG3q2f0vSv0fEwcou\navc7ZVfKPUTZzZsOkPRM2y+alS8GTNO8UTcAGFNHSvpzSb/IrkmnJyi7YudmSd/Jj/mmpPNt7yRp\n5/zmM1J2k5nz8svJ7xERP5CkiHhMkvL3uzoi7s2fX6/sstr/0/zXAqaHZAGU+0ZEnNK7wfYne5+q\n/z0A+t5jo2B9z/om8X8RY45uKKC/SyX9je3dpC03vn+Gsv8zx+bHvFXSFRHxsKSH8isDS9IJkiby\n29+utH1M/h7b214wq98CqAl/zQB9RMQttk+VdHF+I/vHJL1P2Z3oDsv3rVJ2XxUpuyz26bZ3ULpM\nuJQlji/b/nT+HscpOxspnpFw+WeMNS5RDkyB7bURsWjU7QBmG91QwNTw1xU6iTMLAEAlziwAAJVI\nFgCASiQLAEAlkgUAoBLJAgBQiWQBAKj0/zdwzwbCF7WeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1191ec450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = np.array([i[\"train_loss\"] for i in net1.train_history_])\n",
    "valid_loss = np.array([i[\"valid_loss\"] for i in net1.train_history_])\n",
    "plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(1e-0, 1e1)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1513\n",
      "          1       0.20      0.17      0.18     76876\n",
      "          2       0.00      0.00      0.00       406\n",
      "          3       0.00      0.00      0.00       289\n",
      "          4       0.23      0.03      0.06     36755\n",
      "          5       0.29      0.01      0.02      4320\n",
      "          6       0.00      0.00      0.00      2268\n",
      "          7       0.29      0.47      0.36     53971\n",
      "          8       0.00      0.00      0.00      4280\n",
      "          9       0.00      0.00      0.00      1166\n",
      "         10       0.00      0.00      0.00       256\n",
      "         11       0.00      0.00      0.00       491\n",
      "         12       0.17      0.02      0.03     10609\n",
      "         13       0.18      0.01      0.01     16679\n",
      "         14       0.00      0.00      0.00       146\n",
      "         15       0.00      0.00      0.00      2341\n",
      "         16       0.35      0.62      0.45    174900\n",
      "         17       0.00      0.00      0.00      1903\n",
      "         18       0.26      0.01      0.01      1225\n",
      "         19       0.54      0.33      0.41     25989\n",
      "         20       0.25      0.15      0.19     92304\n",
      "         21       0.23      0.43      0.30    126182\n",
      "         22       0.00      0.00      0.00        22\n",
      "         23       0.44      0.59      0.51      7484\n",
      "         24       0.00      0.00      0.00      3138\n",
      "         25       0.20      0.00      0.00     23000\n",
      "         26       0.48      0.18      0.26      1946\n",
      "         27       0.00      0.00      0.00      9985\n",
      "         28       0.00      0.00      0.00      4388\n",
      "         29       0.00      0.00      0.00       148\n",
      "         30       0.00      0.00      0.00      4540\n",
      "         31       0.00      0.00      0.00       508\n",
      "         32       0.12      0.00      0.00     31414\n",
      "         33       0.00      0.00      0.00         6\n",
      "         34       0.24      0.02      0.04      7326\n",
      "         35       0.28      0.01      0.02     44725\n",
      "         36       0.20      0.32      0.25     53781\n",
      "         37       0.13      0.03      0.05     42214\n",
      "         38       0.00      0.00      0.00      8555\n",
      "\n",
      "avg / total       0.25      0.28      0.23    878049\n",
      "\n",
      "The accuracy is: 0.283077595897\n"
     ]
    }
   ],
   "source": [
    "train_pred = net1.predict(np_train_data)\n",
    "print(classification_report(train_labels_int, train_pred))\n",
    "print 'The accuracy is:', accuracy_score(train_labels_int, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.55994418e-04,   5.17634613e-02,   1.74867594e-04,\n",
       "          1.33202890e-04,   1.95734782e-02,   1.48921483e-03,\n",
       "          2.95200712e-03,   8.88459121e-02,   2.66789847e-03,\n",
       "          2.48293490e-04,   1.30072717e-04,   1.88927414e-04,\n",
       "          2.79727962e-03,   7.35410847e-03,   6.48898703e-05,\n",
       "          2.56725077e-03,   2.02256635e-01,   6.92622132e-04,\n",
       "          1.38507262e-04,   1.23984205e-02,   5.58353028e-02,\n",
       "          2.10798437e-01,   2.36708894e-05,   4.52529063e-04,\n",
       "          5.43224795e-04,   2.43055222e-02,   3.40691417e-03,\n",
       "          6.43635260e-03,   3.93389992e-03,   1.11870311e-04,\n",
       "          3.93402599e-03,   4.21033642e-04,   1.01596370e-02,\n",
       "          9.44550728e-06,   1.65134827e-03,   2.66063659e-02,\n",
       "          1.82371662e-01,   6.57369348e-02,   5.96877890e-03]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.predict_proba(np_train_data[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 619 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input         7\n",
      "  1  dense0       10\n",
      "  2  dropout      10\n",
      "  3  dense1       10\n",
      "  4  output       39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m4.14217\u001b[0m       \u001b[32m2.70658\u001b[0m      1.53041      0.19904  2.46s\n",
      "      2       \u001b[36m2.64476\u001b[0m       \u001b[32m2.70492\u001b[0m      0.97776      0.19904  2.82s\n",
      "      3       \u001b[36m2.64386\u001b[0m       \u001b[32m2.70447\u001b[0m      0.97759      0.19904  2.76s\n",
      "      4       \u001b[36m2.64356\u001b[0m       \u001b[32m2.70428\u001b[0m      0.97755      0.19904  2.82s\n",
      "      5       \u001b[36m2.64343\u001b[0m       \u001b[32m2.70418\u001b[0m      0.97753      0.19904  2.74s\n",
      "      6       \u001b[36m2.64335\u001b[0m       \u001b[32m2.70412\u001b[0m      0.97753      0.19904  2.90s\n",
      "      7       \u001b[36m2.64330\u001b[0m       \u001b[32m2.70408\u001b[0m      0.97752      0.19904  2.99s\n",
      "      8       \u001b[36m2.64327\u001b[0m       \u001b[32m2.70406\u001b[0m      0.97752      0.19904  2.91s\n",
      "      9       \u001b[36m2.64324\u001b[0m       \u001b[32m2.70404\u001b[0m      0.97752      0.19904  2.77s\n",
      "     10       \u001b[36m2.64323\u001b[0m       \u001b[32m2.70402\u001b[0m      0.97752      0.19904  2.76s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c727450>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c7273d0>,\n",
       "     custom_score=None, dense0_num_units=10, dense1_num_units=10,\n",
       "     dropout_p=0.5, input_shape=(None, 7),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('dense0', <class 'lasagne.layers.dense.DenseLayer'>), ('dropout', <class 'lasagne.layers.noise.DropoutLayer'>), ('dense1', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=10, more_params={},\n",
       "     objective=<function objective at 0x10c72a938>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c645a28>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x1290f2d40>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x1290f2d88>],\n",
       "     output_nonlinearity=<function softmax at 0x10c4fa140>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c727490>,\n",
       "     update=<function nesterov_momentum at 0x10c656758>,\n",
       "     update_learning_rate=0.02, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tried a more complicated net with layers... still doing the same thing.\n",
    "net2 = NeuralNet(\n",
    "    layers=[  # more layers\n",
    "        ('input', layers.InputLayer),\n",
    "        ('dense0', layers.DenseLayer),\n",
    "        ('dropout', layers.DropoutLayer),\n",
    "        ('dense1', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 7),  # 3 input pixels per batch\n",
    "    dense0_num_units=10,  # number of units in hidden layer\n",
    "    dropout_p=0.5,  # Not sure what this does.....\n",
    "    dense1_num_units=10,  # number of units in hidden layer\n",
    "    output_num_units=39,  # 39 target values\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.02,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=10,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "net2.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(preds):\n",
    "    labels = [\"Id\",\n",
    "                \"ARSON\",\n",
    "                \"ASSAULT\",\n",
    "                \"BAD CHECKS\",\n",
    "                \"BRIBERY\",\n",
    "                \"BURGLARY\",\n",
    "                \"DISORDERLY CONDUCT\",\n",
    "                \"DRIVING UNDER THE INFLUENCE\",\n",
    "                \"DRUG/NARCOTIC\",\n",
    "                \"DRUNKENNESS\",\n",
    "                \"EMBEZZLEMENT\",\n",
    "                \"EXTORTION\",\n",
    "                \"FAMILY OFFENSES\",\n",
    "                \"FORGERY/COUNTERFEITING\",\n",
    "                \"FRAUD\",\n",
    "                \"GAMBLING\",\n",
    "                \"KIDNAPPING\",\n",
    "                \"LARCENY/THEFT\",\n",
    "                \"LIQUOR LAWS\",\n",
    "                \"LOITERING\",\n",
    "                \"MISSING PERSON\",\n",
    "                \"NON-CRIMINAL\",\n",
    "                \"OTHER OFFENSES\",\n",
    "                \"PORNOGRAPHY/OBSCENE MAT\",\n",
    "                \"PROSTITUTION\",\n",
    "                \"RECOVERED VEHICLE\",\n",
    "                \"ROBBERY\",\n",
    "                \"RUNAWAY\",\n",
    "                \"SECONDARY CODES\",\n",
    "                \"SEX OFFENSES FORCIBLE\",\n",
    "                \"SEX OFFENSES NON FORCIBLE\",\n",
    "                \"STOLEN PROPERTY\",\n",
    "                \"SUICIDE\",\n",
    "                \"SUSPICIOUS OCC\",\n",
    "                \"TREA\",\n",
    "                \"TRESPASS\",\n",
    "                \"VANDALISM\",\n",
    "                \"VEHICLE THEFT\",\n",
    "                \"WARRANTS\",\n",
    "                \"WEAPON LAWS\"\n",
    "              ]\n",
    "    head_str = ','.join(labels)\n",
    "\n",
    "    num_cats = len(labels)\n",
    "    \n",
    "    # Make a dummy row to append to\n",
    "    #ids = np.arange(preds.shape[0])[np.newaxis].transpose()\n",
    "    \n",
    "    #results = np.column_stack((ids, preds))\n",
    "\n",
    "    # Write results to csv\n",
    "    str_fmt = \"%d\"\n",
    "    for i in range(0,39):\n",
    "        str_fmt += \",%f\"\n",
    "    np.savetxt('Sample_NN.csv', results, fmt=str_fmt, delimiter=',', header=head_str, comments='')\n",
    "\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 295)\n",
      "(884262, 295)\n"
     ]
    }
   ],
   "source": [
    "# Now that we've done this, let's run the KNN on the full train, apply to the test, then format.\n",
    "#KNNmodel = KNeighborsClassifier(n_neighbors=1)\n",
    "#KNNmodel.fit(full_data, full_labels)\n",
    "#dev_predict = KNNmodel.predict_proba(test_data).astype(int)\n",
    "\n",
    "print np_train_data.shape\n",
    "print np_test_data.shape\n",
    "test_proba = net1.predict_proba(np_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = create_submission(test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884262, 40)\n",
      "%d %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f %f\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print results.shape\n",
    "#print results[0:2]\n",
    "print str_fmt\n",
    "print len(str_fmt)/3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "Old code below here\n",
    "____\n",
    "____\n",
    "____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 254)\n",
      "(878049,)\n",
      "# Neural Network with 147039 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input      254\n",
      "  1  hidden     500\n",
      "  2  output      39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.67321\u001b[0m       \u001b[32m2.66736\u001b[0m      1.00219      0.20197  24.90s\n",
      "      2       \u001b[36m2.56639\u001b[0m       \u001b[32m2.64605\u001b[0m      0.96990      0.20978  24.59s\n",
      "      3       \u001b[36m2.54176\u001b[0m       \u001b[32m2.63234\u001b[0m      0.96559      0.21508  24.00s\n",
      "      4       \u001b[36m2.52726\u001b[0m       \u001b[32m2.62335\u001b[0m      0.96337      0.21664  24.68s\n",
      "      5       \u001b[36m2.51784\u001b[0m       \u001b[32m2.61697\u001b[0m      0.96212      0.21816  24.39s\n",
      "      6       \u001b[36m2.51080\u001b[0m       \u001b[32m2.61196\u001b[0m      0.96127      0.22045  23.91s\n",
      "      7       \u001b[36m2.50493\u001b[0m       \u001b[32m2.60775\u001b[0m      0.96057      0.22372  23.92s\n",
      "      8       \u001b[36m2.49969\u001b[0m       \u001b[32m2.60389\u001b[0m      0.95998      0.22694  23.90s\n",
      "      9       \u001b[36m2.49486\u001b[0m       \u001b[32m2.60038\u001b[0m      0.95942      0.22709  24.10s\n",
      "     10       \u001b[36m2.49034\u001b[0m       \u001b[32m2.59712\u001b[0m      0.95889      0.22724  23.78s\n",
      "     11       \u001b[36m2.48610\u001b[0m       \u001b[32m2.59406\u001b[0m      0.95838      0.22909  23.70s\n",
      "     12       \u001b[36m2.48213\u001b[0m       \u001b[32m2.59122\u001b[0m      0.95790      0.23008  23.79s\n",
      "     13       \u001b[36m2.47841\u001b[0m       \u001b[32m2.58860\u001b[0m      0.95743      0.23017  24.26s\n",
      "     14       \u001b[36m2.47490\u001b[0m       \u001b[32m2.58617\u001b[0m      0.95698      0.23180  24.22s\n",
      "     15       \u001b[36m2.47159\u001b[0m       \u001b[32m2.58384\u001b[0m      0.95656      0.23283  23.58s\n",
      "     16       \u001b[36m2.46845\u001b[0m       \u001b[32m2.58163\u001b[0m      0.95616      0.23391  24.92s\n",
      "     17       \u001b[36m2.46545\u001b[0m       \u001b[32m2.57954\u001b[0m      0.95577      0.23471  23.68s\n",
      "     18       \u001b[36m2.46256\u001b[0m       \u001b[32m2.57753\u001b[0m      0.95539      0.23510  23.62s\n",
      "     19       \u001b[36m2.45978\u001b[0m       \u001b[32m2.57558\u001b[0m      0.95504      0.23541  23.58s\n",
      "     20       \u001b[36m2.45708\u001b[0m       \u001b[32m2.57364\u001b[0m      0.95471      0.23588  24.69s\n",
      "     21       \u001b[36m2.45444\u001b[0m       \u001b[32m2.57175\u001b[0m      0.95438      0.23620  23.78s\n",
      "     22       \u001b[36m2.45186\u001b[0m       \u001b[32m2.56992\u001b[0m      0.95406      0.23663  23.62s\n",
      "     23       \u001b[36m2.44935\u001b[0m       \u001b[32m2.56819\u001b[0m      0.95373      0.23777  25.07s\n",
      "     24       \u001b[36m2.44691\u001b[0m       \u001b[32m2.56647\u001b[0m      0.95341      0.23841  25.80s\n",
      "     25       \u001b[36m2.44452\u001b[0m       \u001b[32m2.56480\u001b[0m      0.95310      0.23901  24.93s\n",
      "     26       \u001b[36m2.44220\u001b[0m       \u001b[32m2.56316\u001b[0m      0.95281      0.24013  25.19s\n",
      "     27       \u001b[36m2.43994\u001b[0m       \u001b[32m2.56159\u001b[0m      0.95251      0.24066  25.25s\n",
      "     28       \u001b[36m2.43773\u001b[0m       \u001b[32m2.56006\u001b[0m      0.95222      0.24114  28.35s\n",
      "     29       \u001b[36m2.43559\u001b[0m       \u001b[32m2.55862\u001b[0m      0.95192      0.24176  25.75s\n",
      "     30       \u001b[36m2.43351\u001b[0m       \u001b[32m2.55727\u001b[0m      0.95161      0.24204  24.77s\n",
      "     31       \u001b[36m2.43148\u001b[0m       \u001b[32m2.55592\u001b[0m      0.95131      0.24335  24.81s\n",
      "     32       \u001b[36m2.42950\u001b[0m       \u001b[32m2.55463\u001b[0m      0.95102      0.24384  24.97s\n",
      "     33       \u001b[36m2.42758\u001b[0m       \u001b[32m2.55342\u001b[0m      0.95072      0.24374  24.77s\n",
      "     34       \u001b[36m2.42571\u001b[0m       \u001b[32m2.55224\u001b[0m      0.95043      0.24414  25.17s\n",
      "     35       \u001b[36m2.42390\u001b[0m       \u001b[32m2.55107\u001b[0m      0.95015      0.24418  24.83s\n",
      "     36       \u001b[36m2.42213\u001b[0m       \u001b[32m2.54999\u001b[0m      0.94986      0.24461  24.75s\n",
      "     37       \u001b[36m2.42041\u001b[0m       \u001b[32m2.54899\u001b[0m      0.94956      0.24480  24.88s\n",
      "     38       \u001b[36m2.41873\u001b[0m       \u001b[32m2.54804\u001b[0m      0.94925      0.24496  24.67s\n",
      "     39       \u001b[36m2.41709\u001b[0m       \u001b[32m2.54712\u001b[0m      0.94895      0.24556  24.66s\n",
      "     40       \u001b[36m2.41551\u001b[0m       \u001b[32m2.54626\u001b[0m      0.94865      0.24607  24.67s\n",
      "     41       \u001b[36m2.41395\u001b[0m       \u001b[32m2.54540\u001b[0m      0.94836      0.24638  24.67s\n",
      "     42       \u001b[36m2.41244\u001b[0m       \u001b[32m2.54461\u001b[0m      0.94806      0.24606  24.66s\n",
      "     43       \u001b[36m2.41097\u001b[0m       \u001b[32m2.54381\u001b[0m      0.94778      0.24603  25.24s\n",
      "     44       \u001b[36m2.40954\u001b[0m       \u001b[32m2.54310\u001b[0m      0.94748      0.24644  24.95s\n",
      "     45       \u001b[36m2.40814\u001b[0m       \u001b[32m2.54240\u001b[0m      0.94719      0.24649  24.68s\n",
      "     46       \u001b[36m2.40678\u001b[0m       \u001b[32m2.54175\u001b[0m      0.94690      0.24660  24.63s\n",
      "     47       \u001b[36m2.40544\u001b[0m       \u001b[32m2.54116\u001b[0m      0.94659      0.24649  24.68s\n",
      "     48       \u001b[36m2.40415\u001b[0m       \u001b[32m2.54059\u001b[0m      0.94629      0.24658  24.62s\n",
      "     49       \u001b[36m2.40289\u001b[0m       \u001b[32m2.54006\u001b[0m      0.94600      0.24695  24.51s\n",
      "     50       \u001b[36m2.40166\u001b[0m       \u001b[32m2.53956\u001b[0m      0.94570      0.24715  24.57s\n",
      "     51       \u001b[36m2.40046\u001b[0m       \u001b[32m2.53906\u001b[0m      0.94541      0.24739  25.44s\n",
      "     52       \u001b[36m2.39929\u001b[0m       \u001b[32m2.53859\u001b[0m      0.94513      0.24753  24.69s\n",
      "     53       \u001b[36m2.39815\u001b[0m       \u001b[32m2.53816\u001b[0m      0.94484      0.24721  24.60s\n",
      "     54       \u001b[36m2.39703\u001b[0m       \u001b[32m2.53767\u001b[0m      0.94458      0.24727  24.56s\n",
      "     55       \u001b[36m2.39594\u001b[0m       \u001b[32m2.53729\u001b[0m      0.94429      0.24735  24.55s\n",
      "     56       \u001b[36m2.39488\u001b[0m       \u001b[32m2.53686\u001b[0m      0.94404      0.24731  24.59s\n",
      "     57       \u001b[36m2.39385\u001b[0m       \u001b[32m2.53648\u001b[0m      0.94377      0.24735  24.58s\n",
      "     58       \u001b[36m2.39283\u001b[0m       \u001b[32m2.53614\u001b[0m      0.94350      0.24798  24.62s\n",
      "     59       \u001b[36m2.39184\u001b[0m       \u001b[32m2.53578\u001b[0m      0.94324      0.24795  24.66s\n",
      "     60       \u001b[36m2.39086\u001b[0m       \u001b[32m2.53547\u001b[0m      0.94297      0.24811  25.02s\n",
      "     61       \u001b[36m2.38991\u001b[0m       \u001b[32m2.53518\u001b[0m      0.94270      0.24822  24.82s\n",
      "     62       \u001b[36m2.38898\u001b[0m       \u001b[32m2.53494\u001b[0m      0.94242      0.24837  24.57s\n",
      "     63       \u001b[36m2.38806\u001b[0m       \u001b[32m2.53467\u001b[0m      0.94216      0.24831  24.70s\n",
      "     64       \u001b[36m2.38717\u001b[0m       \u001b[32m2.53440\u001b[0m      0.94191      0.24835  25.59s\n",
      "     65       \u001b[36m2.38629\u001b[0m       \u001b[32m2.53419\u001b[0m      0.94164      0.24840  24.60s\n",
      "     66       \u001b[36m2.38543\u001b[0m       \u001b[32m2.53396\u001b[0m      0.94138      0.24903  25.10s\n",
      "     67       \u001b[36m2.38458\u001b[0m       \u001b[32m2.53375\u001b[0m      0.94113      0.24913  24.78s\n",
      "     68       \u001b[36m2.38375\u001b[0m       \u001b[32m2.53356\u001b[0m      0.94087      0.24907  24.57s\n",
      "     69       \u001b[36m2.38294\u001b[0m       \u001b[32m2.53333\u001b[0m      0.94063      0.24904  24.59s\n",
      "     70       \u001b[36m2.38215\u001b[0m       \u001b[32m2.53317\u001b[0m      0.94038      0.24907  24.57s\n",
      "     71       \u001b[36m2.38137\u001b[0m       \u001b[32m2.53304\u001b[0m      0.94012      0.24880  25.27s\n",
      "     72       \u001b[36m2.38061\u001b[0m       \u001b[32m2.53286\u001b[0m      0.93989      0.24857  24.75s\n",
      "     73       \u001b[36m2.37986\u001b[0m       \u001b[32m2.53269\u001b[0m      0.93966      0.24847  24.71s\n",
      "     74       \u001b[36m2.37912\u001b[0m       \u001b[32m2.53257\u001b[0m      0.93941      0.24845  24.72s\n",
      "     75       \u001b[36m2.37840\u001b[0m       \u001b[32m2.53245\u001b[0m      0.93917      0.24846  24.76s\n",
      "     76       \u001b[36m2.37768\u001b[0m       \u001b[32m2.53237\u001b[0m      0.93892      0.24834  24.58s\n",
      "     77       \u001b[36m2.37698\u001b[0m       \u001b[32m2.53223\u001b[0m      0.93869      0.24832  24.63s\n",
      "     78       \u001b[36m2.37629\u001b[0m       \u001b[32m2.53213\u001b[0m      0.93846      0.24812  24.67s\n",
      "     79       \u001b[36m2.37562\u001b[0m       \u001b[32m2.53201\u001b[0m      0.93824      0.24816  24.54s\n",
      "     80       \u001b[36m2.37496\u001b[0m       \u001b[32m2.53189\u001b[0m      0.93802      0.24808  24.60s\n",
      "     81       \u001b[36m2.37430\u001b[0m       \u001b[32m2.53183\u001b[0m      0.93778      0.24783  24.69s\n",
      "     82       \u001b[36m2.37367\u001b[0m       \u001b[32m2.53174\u001b[0m      0.93756      0.24785  25.10s\n",
      "     83       \u001b[36m2.37304\u001b[0m       \u001b[32m2.53170\u001b[0m      0.93733      0.24785  26.41s\n",
      "     84       \u001b[36m2.37242\u001b[0m       \u001b[32m2.53166\u001b[0m      0.93710      0.24759  25.89s\n",
      "     85       \u001b[36m2.37181\u001b[0m       \u001b[32m2.53157\u001b[0m      0.93689      0.24756  24.74s\n",
      "     86       \u001b[36m2.37121\u001b[0m       \u001b[32m2.53151\u001b[0m      0.93668      0.24748  24.69s\n",
      "     87       \u001b[36m2.37063\u001b[0m       \u001b[32m2.53150\u001b[0m      0.93645      0.24736  24.80s\n",
      "     88       \u001b[36m2.37005\u001b[0m       \u001b[32m2.53145\u001b[0m      0.93624      0.24714  24.61s\n",
      "     89       \u001b[36m2.36947\u001b[0m       \u001b[32m2.53137\u001b[0m      0.93604      0.24712  24.69s\n",
      "     90       \u001b[36m2.36890\u001b[0m       \u001b[32m2.53135\u001b[0m      0.93582      0.24704  24.59s\n",
      "     91       \u001b[36m2.36834\u001b[0m       \u001b[32m2.53133\u001b[0m      0.93561      0.24733  24.78s\n",
      "     92       \u001b[36m2.36779\u001b[0m       \u001b[32m2.53131\u001b[0m      0.93540      0.24744  24.56s\n",
      "     93       \u001b[36m2.36725\u001b[0m       \u001b[32m2.53127\u001b[0m      0.93520      0.24751  25.47s\n",
      "     94       \u001b[36m2.36672\u001b[0m       \u001b[32m2.53124\u001b[0m      0.93500      0.24753  25.32s\n",
      "     95       \u001b[36m2.36619\u001b[0m       \u001b[32m2.53119\u001b[0m      0.93481      0.24747  24.95s\n",
      "     96       \u001b[36m2.36567\u001b[0m       \u001b[32m2.53118\u001b[0m      0.93461      0.24734  26.04s\n",
      "     97       \u001b[36m2.36516\u001b[0m       \u001b[32m2.53116\u001b[0m      0.93442      0.24746  25.10s\n",
      "     98       \u001b[36m2.36466\u001b[0m       2.53118      0.93421      0.24737  24.98s\n",
      "     99       \u001b[36m2.36416\u001b[0m       2.53117      0.93402      0.24735  24.71s\n",
      "    100       \u001b[36m2.36367\u001b[0m       2.53118      0.93382      0.24713  24.79s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc1d0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc150>,\n",
       "     custom_score=None, hidden_num_units=500, input_shape=(None, 254),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x10c3c5c80>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c1e2c80>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x112c910e0>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x113a6a950>],\n",
       "     output_nonlinearity=<function softmax at 0x10c09c398>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c3cc210>,\n",
       "     update=<function nesterov_momentum at 0x10c1f59b0>,\n",
       "     update_learning_rate=0.002, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_train_data = np.array(pd.concat([data_XRs, data_YRs], axis=1))\n",
    "num_features = np_train_data.shape[1]\n",
    "#The accuracy is: 0.26692018327\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, num_features),  # 3 input pixels per batch\n",
    "    hidden_num_units=500,  # number of units in hidden layer\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    output_num_units=39,  # 39 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.002,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "print np_train_data.shape\n",
    "print train_labels.shape\n",
    "#print len(train_data.columns)\n",
    "net1.fit(np_train_data, train_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 295)\n",
      "(878049,)\n",
      "# Neural Network with 167539 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input      295\n",
      "  1  hidden     500\n",
      "  2  output      39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.63132\u001b[0m       \u001b[32m2.62853\u001b[0m      1.00106      0.22558  29.17s\n",
      "      2       \u001b[36m2.52393\u001b[0m       \u001b[32m2.60553\u001b[0m      0.96868      0.22639  28.61s\n",
      "      3       \u001b[36m2.49870\u001b[0m       \u001b[32m2.59233\u001b[0m      0.96388      0.22789  31.51s\n",
      "      4       \u001b[36m2.48395\u001b[0m       \u001b[32m2.58444\u001b[0m      0.96112      0.22916  26.67s\n",
      "      5       \u001b[36m2.47430\u001b[0m       \u001b[32m2.57896\u001b[0m      0.95942      0.23070  27.25s\n",
      "      6       \u001b[36m2.46697\u001b[0m       \u001b[32m2.57455\u001b[0m      0.95822      0.23279  28.06s\n",
      "      7       \u001b[36m2.46080\u001b[0m       \u001b[32m2.57073\u001b[0m      0.95724      0.23409  27.99s\n",
      "      8       \u001b[36m2.45531\u001b[0m       \u001b[32m2.56732\u001b[0m      0.95637      0.23547  27.81s\n",
      "      9       \u001b[36m2.45030\u001b[0m       \u001b[32m2.56427\u001b[0m      0.95556      0.23653  27.60s\n",
      "     10       \u001b[36m2.44568\u001b[0m       \u001b[32m2.56148\u001b[0m      0.95479      0.23744  26.93s\n",
      "     11       \u001b[36m2.44139\u001b[0m       \u001b[32m2.55897\u001b[0m      0.95405      0.23859  26.67s\n",
      "     12       \u001b[36m2.43737\u001b[0m       \u001b[32m2.55657\u001b[0m      0.95338      0.23904  29.72s\n",
      "     13       \u001b[36m2.43360\u001b[0m       \u001b[32m2.55431\u001b[0m      0.95274      0.23985  27.24s\n",
      "     14       \u001b[36m2.43002\u001b[0m       \u001b[32m2.55220\u001b[0m      0.95213      0.24055  27.29s\n",
      "     15       \u001b[36m2.42661\u001b[0m       \u001b[32m2.55019\u001b[0m      0.95154      0.24150  29.07s\n",
      "     16       \u001b[36m2.42333\u001b[0m       \u001b[32m2.54828\u001b[0m      0.95097      0.24213  30.24s\n",
      "     17       \u001b[36m2.42017\u001b[0m       \u001b[32m2.54638\u001b[0m      0.95043      0.24267  27.23s\n",
      "     18       \u001b[36m2.41712\u001b[0m       \u001b[32m2.54460\u001b[0m      0.94990      0.24355  27.33s\n",
      "     19       \u001b[36m2.41417\u001b[0m       \u001b[32m2.54290\u001b[0m      0.94938      0.24435  27.52s\n",
      "     20       \u001b[36m2.41131\u001b[0m       \u001b[32m2.54123\u001b[0m      0.94888      0.24495  27.29s\n",
      "     21       \u001b[36m2.40854\u001b[0m       \u001b[32m2.53967\u001b[0m      0.94837      0.24582  27.10s\n",
      "     22       \u001b[36m2.40586\u001b[0m       \u001b[32m2.53816\u001b[0m      0.94788      0.24640  27.91s\n",
      "     23       \u001b[36m2.40324\u001b[0m       \u001b[32m2.53670\u001b[0m      0.94739      0.24627  28.08s\n",
      "     24       \u001b[36m2.40069\u001b[0m       \u001b[32m2.53529\u001b[0m      0.94691      0.24670  4407.24s\n",
      "     25       \u001b[36m2.39821\u001b[0m       \u001b[32m2.53401\u001b[0m      0.94641      0.24680  28.19s\n",
      "     26       \u001b[36m2.39579\u001b[0m       \u001b[32m2.53274\u001b[0m      0.94593      0.24729  29.24s\n",
      "     27       \u001b[36m2.39343\u001b[0m       \u001b[32m2.53151\u001b[0m      0.94546      0.24782  29.82s\n",
      "     28       \u001b[36m2.39113\u001b[0m       \u001b[32m2.53035\u001b[0m      0.94498      0.24820  30.04s\n",
      "     29       \u001b[36m2.38889\u001b[0m       \u001b[32m2.52927\u001b[0m      0.94450      0.24825  30.78s\n",
      "     30       \u001b[36m2.38669\u001b[0m       \u001b[32m2.52817\u001b[0m      0.94404      0.24859  30.41s\n",
      "     31       \u001b[36m2.38454\u001b[0m       \u001b[32m2.52710\u001b[0m      0.94359      0.24884  31.39s\n",
      "     32       \u001b[36m2.38243\u001b[0m       \u001b[32m2.52611\u001b[0m      0.94312      0.24911  27.53s\n",
      "     33       \u001b[36m2.38036\u001b[0m       \u001b[32m2.52514\u001b[0m      0.94267      0.24948  28.76s\n",
      "     34       \u001b[36m2.37834\u001b[0m       \u001b[32m2.52425\u001b[0m      0.94220      0.24961  49.17s\n",
      "     35       \u001b[36m2.37637\u001b[0m       \u001b[32m2.52341\u001b[0m      0.94173      0.24987  29.33s\n",
      "     36       \u001b[36m2.37444\u001b[0m       \u001b[32m2.52259\u001b[0m      0.94127      0.25013  29.83s\n",
      "     37       \u001b[36m2.37254\u001b[0m       \u001b[32m2.52183\u001b[0m      0.94080      0.25020  26.78s\n",
      "     38       \u001b[36m2.37068\u001b[0m       \u001b[32m2.52103\u001b[0m      0.94036      0.25020  26.96s\n",
      "     39       \u001b[36m2.36885\u001b[0m       \u001b[32m2.52030\u001b[0m      0.93991      0.25027  30.87s\n",
      "     40       \u001b[36m2.36705\u001b[0m       \u001b[32m2.51957\u001b[0m      0.93947      0.25053  27.50s\n",
      "     41       \u001b[36m2.36528\u001b[0m       \u001b[32m2.51887\u001b[0m      0.93903      0.25089  27.18s\n",
      "     42       \u001b[36m2.36355\u001b[0m       \u001b[32m2.51823\u001b[0m      0.93858      0.25107  29.37s\n",
      "     43       \u001b[36m2.36184\u001b[0m       \u001b[32m2.51756\u001b[0m      0.93815      0.25125  30.24s\n",
      "     44       \u001b[36m2.36016\u001b[0m       \u001b[32m2.51698\u001b[0m      0.93770      0.25145  30.64s\n",
      "     45       \u001b[36m2.35852\u001b[0m       \u001b[32m2.51643\u001b[0m      0.93725      0.25168  30.63s\n",
      "     46       \u001b[36m2.35689\u001b[0m       \u001b[32m2.51588\u001b[0m      0.93681      0.25164  30.11s\n",
      "     47       \u001b[36m2.35530\u001b[0m       \u001b[32m2.51533\u001b[0m      0.93638      0.25181  29.28s\n",
      "     48       \u001b[36m2.35373\u001b[0m       \u001b[32m2.51483\u001b[0m      0.93594      0.25187  28.52s\n",
      "     49       \u001b[36m2.35218\u001b[0m       \u001b[32m2.51435\u001b[0m      0.93550      0.25205  28.39s\n",
      "     50       \u001b[36m2.35065\u001b[0m       \u001b[32m2.51388\u001b[0m      0.93507      0.25213  28.93s\n",
      "     51       \u001b[36m2.34915\u001b[0m       \u001b[32m2.51346\u001b[0m      0.93463      0.25210  29.59s\n",
      "     52       \u001b[36m2.34766\u001b[0m       \u001b[32m2.51303\u001b[0m      0.93420      0.25217  29.65s\n",
      "     53       \u001b[36m2.34620\u001b[0m       \u001b[32m2.51266\u001b[0m      0.93375      0.25241  30.83s\n",
      "     54       \u001b[36m2.34477\u001b[0m       \u001b[32m2.51230\u001b[0m      0.93332      0.25224  30.00s\n",
      "     55       \u001b[36m2.34335\u001b[0m       \u001b[32m2.51198\u001b[0m      0.93287      0.25257  29.21s\n",
      "     56       \u001b[36m2.34195\u001b[0m       \u001b[32m2.51170\u001b[0m      0.93242      0.25240  29.62s\n",
      "     57       \u001b[36m2.34057\u001b[0m       \u001b[32m2.51147\u001b[0m      0.93196      0.25228  28.76s\n",
      "     58       \u001b[36m2.33922\u001b[0m       \u001b[32m2.51120\u001b[0m      0.93151      0.25227  28.92s\n",
      "     59       \u001b[36m2.33787\u001b[0m       \u001b[32m2.51098\u001b[0m      0.93106      0.25253  29.89s\n",
      "     60       \u001b[36m2.33654\u001b[0m       \u001b[32m2.51077\u001b[0m      0.93061      0.25246  29.51s\n",
      "     61       \u001b[36m2.33523\u001b[0m       \u001b[32m2.51064\u001b[0m      0.93013      0.25251  29.18s\n",
      "     62       \u001b[36m2.33394\u001b[0m       \u001b[32m2.51044\u001b[0m      0.92969      0.25244  29.61s\n",
      "     63       \u001b[36m2.33267\u001b[0m       \u001b[32m2.51032\u001b[0m      0.92923      0.25240  30.16s\n",
      "     64       \u001b[36m2.33141\u001b[0m       \u001b[32m2.51018\u001b[0m      0.92878      0.25235  28.81s\n",
      "     65       \u001b[36m2.33016\u001b[0m       \u001b[32m2.51004\u001b[0m      0.92833      0.25244  29.82s\n",
      "     66       \u001b[36m2.32892\u001b[0m       \u001b[32m2.50993\u001b[0m      0.92789      0.25248  46.72s\n",
      "     67       \u001b[36m2.32770\u001b[0m       \u001b[32m2.50982\u001b[0m      0.92744      0.25237  30.61s\n",
      "     68       \u001b[36m2.32650\u001b[0m       \u001b[32m2.50974\u001b[0m      0.92699      0.25250  30.36s\n",
      "     69       \u001b[36m2.32531\u001b[0m       \u001b[32m2.50968\u001b[0m      0.92653      0.25259  31.22s\n",
      "     70       \u001b[36m2.32413\u001b[0m       \u001b[32m2.50963\u001b[0m      0.92608      0.25267  27.88s\n",
      "     71       \u001b[36m2.32296\u001b[0m       \u001b[32m2.50953\u001b[0m      0.92566      0.25256  29.52s\n",
      "     72       \u001b[36m2.32181\u001b[0m       \u001b[32m2.50949\u001b[0m      0.92521      0.25259  28.82s\n",
      "     73       \u001b[36m2.32068\u001b[0m       \u001b[32m2.50944\u001b[0m      0.92478      0.25265  27.80s\n",
      "     74       \u001b[36m2.31954\u001b[0m       \u001b[32m2.50942\u001b[0m      0.92434      0.25265  28.35s\n",
      "     75       \u001b[36m2.31843\u001b[0m       \u001b[32m2.50941\u001b[0m      0.92389      0.25269  29.45s\n",
      "     76       \u001b[36m2.31732\u001b[0m       \u001b[32m2.50934\u001b[0m      0.92348      0.25270  29.53s\n",
      "     77       \u001b[36m2.31623\u001b[0m       \u001b[32m2.50933\u001b[0m      0.92305      0.25267  28.33s\n",
      "     78       \u001b[36m2.31516\u001b[0m       2.50935      0.92261      0.25267  28.09s\n",
      "     79       \u001b[36m2.31409\u001b[0m       2.50938      0.92218      0.25270  28.99s\n",
      "     80       \u001b[36m2.31303\u001b[0m       2.50942      0.92174      0.25261  28.21s\n",
      "     81       \u001b[36m2.31199\u001b[0m       2.50939      0.92134      0.25285  28.68s\n",
      "     82       \u001b[36m2.31096\u001b[0m       2.50944      0.92091      0.25270  30.92s\n",
      "     83       \u001b[36m2.30995\u001b[0m       2.50953      0.92047      0.25258  30.43s\n",
      "     84       \u001b[36m2.30894\u001b[0m       2.50960      0.92004      0.25258  18999.85s\n",
      "     85       \u001b[36m2.30794\u001b[0m       2.50970      0.91961      0.25254  29.23s\n",
      "     86       \u001b[36m2.30695\u001b[0m       2.50979      0.91918      0.25241  29.50s\n",
      "     87       \u001b[36m2.30597\u001b[0m       2.50985      0.91877      0.25245  29.28s\n",
      "     88       \u001b[36m2.30500\u001b[0m       2.50997      0.91834      0.25255  27.56s\n",
      "     89       \u001b[36m2.30403\u001b[0m       2.51006      0.91792      0.25271  27.81s\n",
      "     90       \u001b[36m2.30308\u001b[0m       2.51015      0.91751      0.25261  29.33s\n",
      "     91       \u001b[36m2.30214\u001b[0m       2.51030      0.91708      0.25252  28.20s\n",
      "     92       \u001b[36m2.30121\u001b[0m       2.51040      0.91667      0.25247  27.98s\n",
      "     93       \u001b[36m2.30029\u001b[0m       2.51054      0.91625      0.25225  27.74s\n",
      "     94       \u001b[36m2.29937\u001b[0m       2.51072      0.91582      0.25214  27.73s\n",
      "     95       \u001b[36m2.29847\u001b[0m       2.51084      0.91542      0.25233  27.96s\n",
      "     96       \u001b[36m2.29758\u001b[0m       2.51095      0.91502      0.25228  28.06s\n",
      "     97       \u001b[36m2.29669\u001b[0m       2.51111      0.91461      0.25209  27.71s\n",
      "     98       \u001b[36m2.29582\u001b[0m       2.51128      0.91420      0.25209  27.66s\n",
      "     99       \u001b[36m2.29495\u001b[0m       2.51147      0.91379      0.25208  28.68s\n",
      "    100       \u001b[36m2.29410\u001b[0m       2.51159      0.91340      0.25211  27.92s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc1d0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc150>,\n",
       "     custom_score=None, hidden_num_units=500, input_shape=(None, 295),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x10c3c5c80>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c1e2c80>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x114963878>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x114aeb710>],\n",
       "     output_nonlinearity=<function softmax at 0x10c09c398>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c3cc210>,\n",
       "     update=<function nesterov_momentum at 0x10c1f59b0>,\n",
       "     update_learning_rate=0.002, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "# The accuracy is: 0.283077595897\n",
    "# Should run again stopping early @ 77 for better results\n",
    "num_features = np_train_data.shape[1]\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, num_features),  # 3 input pixels per batch\n",
    "    hidden_num_units=500,  # number of units in hidden layer\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    output_num_units=39,  # 39 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.002,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "print np_train_data.shape\n",
    "print train_labels.shape\n",
    "#print len(train_data.columns)\n",
    "net1.fit(np_train_data, train_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 296)\n",
      "(884262, 308)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 296)\n",
      "(878049,)\n",
      "# Neural Network with 168039 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input      296\n",
      "  1  hidden     500\n",
      "  2  output      39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.62875\u001b[0m       \u001b[32m2.62633\u001b[0m      1.00092      0.22510  29.49s\n",
      "      2       \u001b[36m2.52224\u001b[0m       \u001b[32m2.60240\u001b[0m      0.96920      0.22908  29.07s\n",
      "      3       \u001b[36m2.49736\u001b[0m       \u001b[32m2.58764\u001b[0m      0.96511      0.23085  30.53s\n",
      "      4       \u001b[36m2.48292\u001b[0m       \u001b[32m2.57807\u001b[0m      0.96309      0.23283  32.36s\n",
      "      5       \u001b[36m2.47333\u001b[0m       \u001b[32m2.57122\u001b[0m      0.96193      0.23478  30.58s\n",
      "      6       \u001b[36m2.46596\u001b[0m       \u001b[32m2.56577\u001b[0m      0.96110      0.23661  29.43s\n",
      "      7       \u001b[36m2.45976\u001b[0m       \u001b[32m2.56136\u001b[0m      0.96033      0.23805  27.92s\n",
      "      8       \u001b[36m2.45424\u001b[0m       \u001b[32m2.55749\u001b[0m      0.95963      0.23935  27.95s\n",
      "      9       \u001b[36m2.44921\u001b[0m       \u001b[32m2.55418\u001b[0m      0.95890      0.24044  28.26s\n",
      "     10       \u001b[36m2.44456\u001b[0m       \u001b[32m2.55124\u001b[0m      0.95818      0.24127  28.62s\n",
      "     11       \u001b[36m2.44022\u001b[0m       \u001b[32m2.54858\u001b[0m      0.95748      0.24231  28.57s\n",
      "     12       \u001b[36m2.43614\u001b[0m       \u001b[32m2.54617\u001b[0m      0.95679      0.24372  27.71s\n",
      "     13       \u001b[36m2.43229\u001b[0m       \u001b[32m2.54374\u001b[0m      0.95619      0.24480  30.99s\n",
      "     14       \u001b[36m2.42862\u001b[0m       \u001b[32m2.54142\u001b[0m      0.95562      0.24607  28.61s\n",
      "     15       \u001b[36m2.42513\u001b[0m       \u001b[32m2.53924\u001b[0m      0.95506      0.24678  28.15s\n",
      "     16       \u001b[36m2.42178\u001b[0m       \u001b[32m2.53721\u001b[0m      0.95450      0.24760  27.99s\n",
      "     17       \u001b[36m2.41856\u001b[0m       \u001b[32m2.53518\u001b[0m      0.95400      0.24827  29.83s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc1d0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc150>,\n",
       "     custom_score=None, hidden_num_units=500, input_shape=(None, 296),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x10c3c5c80>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c1e2c80>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x114b3a758>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x1171d6290>],\n",
       "     output_nonlinearity=<function softmax at 0x10c09c398>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c3cc210>,\n",
       "     update=<function nesterov_momentum at 0x10c1f59b0>,\n",
       "     update_learning_rate=0.002, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "# np_train_data = np.array(pd.concat([train_data[features], (data.Year < 2008) * 1, data_XRs, data_YRs], axis=1))\n",
    "\n",
    "num_features = np_train_data.shape[1]\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, num_features),  # 3 input pixels per batch\n",
    "    hidden_num_units=500,  # number of units in hidden layer\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    output_num_units=39,  # 39 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.002,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "print np_train_data.shape\n",
    "print train_labels.shape\n",
    "#print len(train_data.columns)\n",
    "net1.fit(np_train_data, train_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 297)\n",
      "(878049,)\n",
      "# Neural Network with 168539 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input      297\n",
      "  1  hidden     500\n",
      "  2  output      39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.62592\u001b[0m       \u001b[32m2.62294\u001b[0m      1.00114      0.22713  29.77s\n",
      "      2       \u001b[36m2.51960\u001b[0m       \u001b[32m2.59705\u001b[0m      0.97018      0.22995  31.28s\n",
      "      3       \u001b[36m2.49565\u001b[0m       \u001b[32m2.58266\u001b[0m      0.96631      0.23189  30.75s\n",
      "      4       \u001b[36m2.48211\u001b[0m       \u001b[32m2.57427\u001b[0m      0.96420      0.23377  32.86s\n",
      "      5       \u001b[36m2.47307\u001b[0m       \u001b[32m2.56915\u001b[0m      0.96261      0.23547  28.59s\n",
      "      6       \u001b[36m2.46605\u001b[0m       \u001b[32m2.56581\u001b[0m      0.96112      0.23733  28.48s\n",
      "      7       \u001b[36m2.46002\u001b[0m       \u001b[32m2.56332\u001b[0m      0.95970      0.23939  29.78s\n",
      "      8       \u001b[36m2.45459\u001b[0m       \u001b[32m2.56129\u001b[0m      0.95834      0.24093  28.83s\n",
      "      9       \u001b[36m2.44958\u001b[0m       \u001b[32m2.55955\u001b[0m      0.95703      0.24215  28.69s\n",
      "     10       \u001b[36m2.44492\u001b[0m       \u001b[32m2.55793\u001b[0m      0.95582      0.24364  31.31s\n",
      "     11       \u001b[36m2.44056\u001b[0m       \u001b[32m2.55616\u001b[0m      0.95477      0.24489  30.43s\n",
      "     12       \u001b[36m2.43645\u001b[0m       \u001b[32m2.55446\u001b[0m      0.95380      0.24605  32.35s\n",
      "     13       \u001b[36m2.43256\u001b[0m       \u001b[32m2.55269\u001b[0m      0.95294      0.24704  29.12s\n",
      "     14       \u001b[36m2.42884\u001b[0m       \u001b[32m2.55100\u001b[0m      0.95211      0.24797  28.51s\n",
      "     15       \u001b[36m2.42528\u001b[0m       \u001b[32m2.54934\u001b[0m      0.95134      0.24900  28.80s\n",
      "     16       \u001b[36m2.42185\u001b[0m       \u001b[32m2.54758\u001b[0m      0.95065      0.24947  32.57s\n",
      "     17       \u001b[36m2.41856\u001b[0m       \u001b[32m2.54595\u001b[0m      0.94996      0.25033  28.59s\n",
      "     18       \u001b[36m2.41539\u001b[0m       \u001b[32m2.54426\u001b[0m      0.94935      0.25108  28.54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc1d0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc150>,\n",
       "     custom_score=None, hidden_num_units=500, input_shape=(None, 297),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x10c3c5c80>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c1e2c80>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x12193a128>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x121938098>],\n",
       "     output_nonlinearity=<function softmax at 0x10c09c398>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c3cc210>,\n",
       "     update=<function nesterov_momentum at 0x10c1f59b0>,\n",
       "     update_learning_rate=0.002, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "# np_train_data = np.array(pd.concat([train_data[features], (data.Year < 2008) * 1, (data.Year < 2010) * 1, data_XRs, data_YRs], axis=1))\n",
    "num_features = np_train_data.shape[1]\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, num_features),  # 3 input pixels per batch\n",
    "    hidden_num_units=500,  # number of units in hidden layer\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    output_num_units=39,  # 39 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.002,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "print np_train_data.shape\n",
    "print train_labels.shape\n",
    "#print len(train_data.columns)\n",
    "net1.fit(np_train_data, train_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 298)\n",
      "(878049,)\n",
      "# Neural Network with 169039 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input      298\n",
      "  1  hidden     500\n",
      "  2  output      39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.62809\u001b[0m       \u001b[32m2.62996\u001b[0m      0.99929      0.22293  29.86s\n",
      "      2       \u001b[36m2.52001\u001b[0m       \u001b[32m2.60081\u001b[0m      0.96893      0.22731  31.13s\n",
      "      3       \u001b[36m2.49587\u001b[0m       \u001b[32m2.58352\u001b[0m      0.96607      0.23178  31.61s\n",
      "      4       \u001b[36m2.48171\u001b[0m       \u001b[32m2.57370\u001b[0m      0.96426      0.23485  35.16s\n",
      "      5       \u001b[36m2.47211\u001b[0m       \u001b[32m2.56818\u001b[0m      0.96259      0.23673  29.39s\n",
      "      6       \u001b[36m2.46465\u001b[0m       \u001b[32m2.56479\u001b[0m      0.96096      0.23867  28.68s\n",
      "      7       \u001b[36m2.45834\u001b[0m       \u001b[32m2.56239\u001b[0m      0.95939      0.23985  29.94s\n",
      "      8       \u001b[36m2.45272\u001b[0m       \u001b[32m2.56042\u001b[0m      0.95794      0.24137  29.30s\n",
      "      9       \u001b[36m2.44761\u001b[0m       \u001b[32m2.55861\u001b[0m      0.95662      0.24299  29.00s\n",
      "     10       \u001b[36m2.44287\u001b[0m       \u001b[32m2.55680\u001b[0m      0.95544      0.24424  28.97s\n",
      "     11       \u001b[36m2.43847\u001b[0m       \u001b[32m2.55493\u001b[0m      0.95442      0.24550  28.80s\n",
      "     12       \u001b[36m2.43433\u001b[0m       \u001b[32m2.55309\u001b[0m      0.95349      0.24651  29.12s\n",
      "     13       \u001b[36m2.43042\u001b[0m       \u001b[32m2.55134\u001b[0m      0.95261      0.24754  29.28s\n",
      "     14       \u001b[36m2.42669\u001b[0m       \u001b[32m2.54960\u001b[0m      0.95179      0.24877  28.72s\n",
      "     15       \u001b[36m2.42312\u001b[0m       \u001b[32m2.54787\u001b[0m      0.95104      0.24942  28.79s\n",
      "     16       \u001b[36m2.41969\u001b[0m       \u001b[32m2.54619\u001b[0m      0.95032      0.25034  28.69s\n",
      "     17       \u001b[36m2.41637\u001b[0m       \u001b[32m2.54457\u001b[0m      0.94962      0.25101  29.19s\n",
      "     18       \u001b[36m2.41317\u001b[0m       \u001b[32m2.54301\u001b[0m      0.94894      0.25175  28.79s\n",
      "     19       \u001b[36m2.41008\u001b[0m       \u001b[32m2.54149\u001b[0m      0.94829      0.25247  29.27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc1d0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc150>,\n",
       "     custom_score=None, hidden_num_units=500, input_shape=(None, 298),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x10c3c5c80>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c1e2c80>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x11c653fc8>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x11c659cf8>],\n",
       "     output_nonlinearity=<function softmax at 0x10c09c398>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c3cc210>,\n",
       "     update=<function nesterov_momentum at 0x10c1f59b0>,\n",
       "     update_learning_rate=0.002, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "# np_train_data = np.array(pd.concat([train_data[features], (data.Year < 2006) * 1, (data.Year < 2008) * 1, (data.Year < 2010) * 1, data_XRs, data_YRs], axis=1))\n",
    "num_features = np_train_data.shape[1]\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, num_features),  # 3 input pixels per batch\n",
    "    hidden_num_units=500,  # number of units in hidden layer\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    output_num_units=39,  # 39 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.002,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "print np_train_data.shape\n",
    "print train_labels.shape\n",
    "#print len(train_data.columns)\n",
    "net1.fit(np_train_data, train_labels_int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
