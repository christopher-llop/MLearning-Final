{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Neural Net libraries. \n",
    "# I installed the live version of lasagne, theano, and nolearn directly from git. Follow this instructions here:\n",
    "# https://github.com/dnouri/nolearn\n",
    "from lasagne import layers\n",
    "from lasagne import nonlinearities\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "# Function to print all pandas rows\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    pd.set_option('display.max_columns', len(x.columns))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/cjllop/Code/MIDS/MLearning/Final/Data/train.csv\")\n",
    "test = pd.read_csv(\"/Users/cjllop/Code/MIDS/MLearning/Final/Data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "(878049, 9)\n",
      "['Dates' 'Category' 'Descript' 'DayOfWeek' 'PdDistrict' 'Resolution'\n",
      " 'Address' 'X' 'Y']\n",
      "Test Data:\n",
      "(884262, 7)\n",
      "['Id' 'Dates' 'DayOfWeek' 'PdDistrict' 'Address' 'X' 'Y']\n"
     ]
    }
   ],
   "source": [
    "# Big Picture of Data\n",
    "print \"Train Data:\"\n",
    "print data.shape\n",
    "print data.columns.values\n",
    "print \"Test Data:\"\n",
    "print test.shape\n",
    "print test.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dates' 'Category' 'Descript' 'DayOfWeek' 'PdDistrict' 'Resolution'\n",
      " 'Address' 'X' 'Y' 'DateTime' 'DateDiff' 'Year' 'Month' 'Day' 'Hour'\n",
      " 'SecondsDelta' 'Weekend' 'XR' 'YR' '2003' '2004' '2005' '2006' '2007'\n",
      " '2008' '2009' '2010' '2011' '2012' '2013' '2014' '2015' 'Jan' 'Feb' 'Mar'\n",
      " 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec' '1' '2' '3' '4' '5'\n",
      " '6' '7' '8' '9' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '20'\n",
      " '21' '22' '23' '24' '25' '26' '27' '28' '29' '30' '31' 'Friday' 'Monday'\n",
      " 'Saturday' 'Sunday' 'Thursday' 'Tuesday' 'Wednesday' '12AM' '1AM' '2AM'\n",
      " '3AM' '4AM' '5AM' '6AM' '7AM' '8AM' '9AM' '10AM' '11AM' '12PM' '1PM' '2PM'\n",
      " '3PM' '4PM' '5PM' '6PM' '7PM' '8PM' '9PM' '10PM' '11PM' 'BAYVIEW'\n",
      " 'CENTRAL' 'INGLESIDE' 'MISSION' 'NORTHERN' 'PARK' 'RICHMOND' 'SOUTHERN'\n",
      " 'TARAVAL' 'TENDERLOIN']\n",
      "['-120.5' '-122.365' '-122.366' '-122.37' '-122.371' '-122.372' '-122.373'\n",
      " '-122.374' '-122.375' '-122.376' '-122.377' '-122.378' '-122.379'\n",
      " '-122.38' '-122.381' '-122.382' '-122.383' '-122.384' '-122.385'\n",
      " '-122.386' '-122.387' '-122.388' '-122.389' '-122.39' '-122.391'\n",
      " '-122.392' '-122.393' '-122.394' '-122.395' '-122.396' '-122.397'\n",
      " '-122.398' '-122.399' '-122.4' '-122.401' '-122.402' '-122.403' '-122.404'\n",
      " '-122.405' '-122.406' '-122.407' '-122.408' '-122.409' '-122.41'\n",
      " '-122.411' '-122.412' '-122.413' '-122.414' '-122.415' '-122.416'\n",
      " '-122.417' '-122.418' '-122.419' '-122.42' '-122.421' '-122.422'\n",
      " '-122.423' '-122.424' '-122.425' '-122.426' '-122.427' '-122.428'\n",
      " '-122.429' '-122.43' '-122.431' '-122.432' '-122.433' '-122.434'\n",
      " '-122.435' '-122.436' '-122.437' '-122.438' '-122.439' '-122.44'\n",
      " '-122.441' '-122.442' '-122.443' '-122.444' '-122.445' '-122.446'\n",
      " '-122.447' '-122.448' '-122.449' '-122.45' '-122.451' '-122.452'\n",
      " '-122.453' '-122.454' '-122.455' '-122.456' '-122.457' '-122.458'\n",
      " '-122.459' '-122.46' '-122.461' '-122.462' '-122.463' '-122.464'\n",
      " '-122.465' '-122.466' '-122.467' '-122.468' '-122.469' '-122.47'\n",
      " '-122.471' '-122.472' '-122.473' '-122.474' '-122.475' '-122.476'\n",
      " '-122.477' '-122.478' '-122.479' '-122.48' '-122.481' '-122.482'\n",
      " '-122.483' '-122.484' '-122.485' '-122.486' '-122.487' '-122.488'\n",
      " '-122.489' '-122.49' '-122.491' '-122.492' '-122.493' '-122.494'\n",
      " '-122.495' '-122.496' '-122.497' '-122.498' '-122.499' '-122.5' '-122.501'\n",
      " '-122.502' '-122.503' '-122.504' '-122.505' '-122.506' '-122.507'\n",
      " '-122.508' '-122.509' '-122.51' '-122.511' '-122.512' '-122.514']\n",
      "['37.708' '37.709' '37.71' '37.711' '37.712' '37.713' '37.714' '37.715'\n",
      " '37.716' '37.717' '37.718' '37.719' '37.72' '37.721' '37.722' '37.723'\n",
      " '37.724' '37.725' '37.726' '37.727' '37.728' '37.729' '37.73' '37.731'\n",
      " '37.732' '37.733' '37.734' '37.735' '37.736' '37.737' '37.738' '37.739'\n",
      " '37.74' '37.741' '37.742' '37.743' '37.744' '37.745' '37.746' '37.747'\n",
      " '37.748' '37.749' '37.75' '37.751' '37.752' '37.753' '37.754' '37.755'\n",
      " '37.756' '37.757' '37.758' '37.759' '37.76' '37.761' '37.762' '37.763'\n",
      " '37.764' '37.765' '37.766' '37.767' '37.768' '37.769' '37.77' '37.771'\n",
      " '37.772' '37.773' '37.774' '37.775' '37.776' '37.777' '37.778' '37.779'\n",
      " '37.78' '37.781' '37.782' '37.783' '37.784' '37.785' '37.786' '37.787'\n",
      " '37.788' '37.789' '37.79' '37.791' '37.792' '37.793' '37.794' '37.795'\n",
      " '37.796' '37.797' '37.798' '37.799' '37.8' '37.801' '37.802' '37.803'\n",
      " '37.804' '37.805' '37.806' '37.807' '37.808' '37.809' '37.81' '37.815'\n",
      " '37.817' '37.82' '90.0']\n"
     ]
    }
   ],
   "source": [
    "# Extract new features here because it's easier in Pandas than NumPy\n",
    "def build_features(data):\n",
    "    data['DateTime'] = pd.to_datetime(data['Dates'])\n",
    "    date_vector = data['DateTime'].dt.date\n",
    "    data['DateDiff'] = (date_vector - date_vector.min()) / np.timedelta64(1, 'D')\n",
    "    data['Year'] = pd.DatetimeIndex(data['DateTime']).year\n",
    "    data['Month'] = pd.DatetimeIndex(data['DateTime']).month\n",
    "    data['Day'] = pd.DatetimeIndex(data['DateTime']).day\n",
    "    data['Hour'] = pd.DatetimeIndex(data['DateTime']).hour\n",
    "    data['SecondsDelta'] = (data.DateTime - pd.Timestamp('2013-01-01')) / np.timedelta64(1,'s')\n",
    "    data['Weekend'] = (data.DayOfWeek == \"Saturday\") | (data.DayOfWeek == \"Sunday\")\n",
    "    data['XR'] = data['X'].round(decimals=3).apply(str)\n",
    "    data['YR'] = data['Y'].round(decimals=3).apply(str)\n",
    "    years = pd.get_dummies(data.Year)\n",
    "    years.columns = ['2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "    months = pd.get_dummies(data.Month)\n",
    "    months.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    days = pd.get_dummies(data.Day)\n",
    "    days.columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "    daysofweek = pd.get_dummies(data.DayOfWeek)\n",
    "    hours = pd.get_dummies(data.Hour)\n",
    "    hours.columns = ['12AM', '1AM', '2AM', '3AM', '4AM', '5AM',\n",
    "                     '6AM', '7AM', '8AM', '9AM', '10AM', '11AM',\n",
    "                     '12PM', '1PM', '2PM', '3PM', '4PM', '5PM',\n",
    "                     '6PM', '7PM', '8PM', '9PM', '10PM', '11PM']\n",
    "    districts = pd.get_dummies(data.PdDistrict)\n",
    "    new_data = pd.concat([data, years, months, days, daysofweek, hours, districts], axis=1)\n",
    "    return new_data\n",
    "\n",
    "#data = build_features(data)\n",
    "data_XRs = pd.get_dummies(data.XR)\n",
    "data_YRs = pd.get_dummies(data.YR)    \n",
    "#test = build_features(test)\n",
    "\n",
    "print data.columns.values\n",
    "print data_XRs.columns.values\n",
    "print data_YRs.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate labels\n",
    "train_labels = data.Category\n",
    "\n",
    "# Create integer labels\n",
    "panda_labels = pd.Categorical(data.Category).codes\n",
    "train_labels_int = np.array(panda_labels).astype(np.int32)\n",
    "\n",
    "# Drop Category, Descript and Resolution columns since we cannot use them to predict\n",
    "train_data = data.drop(['Category', 'Descript', 'Resolution', 'DateTime', 'Dates', 'PdDistrict', 'Address', 'DayOfWeek'], axis=1)\n",
    "train_data.Weekend = train_data.Weekend * 1\n",
    "train_names = train_data.columns.values.tolist()\n",
    "test_names = test.columns.values.tolist()\n",
    "\n",
    "#print_full(train_data.head(5))\n",
    "\n",
    "#print_full(pd.DataFrame(train_data.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO \n",
    "data_address_dummies = pd.get_dummies(data.Address,sparse=True)\n",
    "#test_address_dummies = pd.get_dummies(test.Address,sparse=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO \n",
    "\n",
    "#print pd.concat([data, pd.get_dummies(data.PdDistrict, prefix=\"PdDistrict\")], axis=1)\n",
    "\n",
    "# Let's create dummy variables for any address with over 100 events.\n",
    "address_counts = data[\"Address\"].value_counts()\n",
    "address_list = pd.Series(address_counts[address_counts > 100].index).to_frame(\"Address\")\n",
    "#print len(address_counts)\n",
    "#print len(address_counts[address_counts > 100])\n",
    "#address_list.columns.values = [\"Address\"]\n",
    "#print pd.DataFrame(address_list).columns.values\n",
    "#print data.columns.values\n",
    "#print address_list\n",
    "top_address = pd.merge(data, address_list, how='inner', on=['Address'])\n",
    "#top_address['temp'] = 1\n",
    "#bottom_address = pd.merge(data, top_address, how='left', on=['Address'])\n",
    "print data.shape\n",
    "print result.shape\n",
    "#print bottom_address.shape\n",
    "\n",
    "#address_counts[address_counts > 100].index.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lasagne works off of Theano instead of Numpy\n",
    "#print data.Category\n",
    "#train_data = np.array(data[['X','Y','Year','Month','Day','Hour','DayOfYear']].values)\n",
    "#train_data = np.array(data_features)\n",
    "\n",
    "#panda_labels = pd.Categorical(data.Category).labels\n",
    "#train_labels = np.array(panda_labels).astype(np.int32)\n",
    "#print train_labels\n",
    "#print train_data.groupby(level=0).first()\n",
    "#print train_data.index.get_duplicates()\n",
    "#print train_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(790245, 10)\n",
      "(87804, 10)\n",
      "(884262, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create random dev sample so we can see how that accuracy compares to our Kaggle results\n",
    "# np.random.seed(100)\n",
    "\n",
    "# Pick 10% of rows for dev\n",
    "# rows = np.random.choice(data.index, size = len(data) / 10, replace = False)\n",
    "\n",
    "# dev = data.ix[rows]\n",
    "# train = data.drop(rows)\n",
    "\n",
    "# print train.shape\n",
    "# print dev.shape\n",
    "# print test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features = [\n",
    " 'X', 'Y', 'DateDiff', 'Year', 'Month', 'Day', 'Hour',\n",
    " 'SecondsDelta', 'Weekend', '2003', '2004', '2005', '2006', '2007', '2008', '2009',\n",
    " '2010', '2011', '2012', '2013', '2014', '2015', 'Jan', 'Feb', 'Mar', 'Apr', 'May',\n",
    " 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    " '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',\n",
    " '24', '25', '26', '27', '28', '29', '30', '31', 'Friday', 'Monday', 'Saturday',\n",
    " 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM',\n",
    " '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM',\n",
    " '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL',\n",
    " 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL',\n",
    " 'TENDERLOIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "#features = ['X', 'Y'] #???? | ???? | 2.69680 | 0.1871\n",
    "#features = ['X', 'Y', 'DateDiff'] #2.73877 | 2.69913 | 2.69680 | 0.199\n",
    "#features = ['X', 'Y', 'DateDiff', 'Year', 'Month', 'Day', 'Hour', 'Weekend'] #2.73866 | 2.69914 || 0.199\n",
    "#features = ['X', 'Y', 'Year', 'Month', 'Day', 'Hour', 'Weekend'] #2.73870\n",
    "#features = ['Year', 'Month', 'Day', 'Hour', 'Weekend'] #2.73867\n",
    "#features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',] # 2.70496\n",
    "features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "#2.64560 | 2.62009 | 0.174%\n",
    "#features = ['2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "#2.71693|||0.20055\n",
    "#[(200,10) = 0.231704608741]\n",
    "#[(500,20) = 0.240513912094]\n",
    "#features = ['2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', 'Jan', 'Feb', 'Mar', 'Apr', 'May',  'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',  '24', '25', '26', '27', '28', '29', '30', '31', 'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM',  '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "\n",
    "\n",
    "#np_train_data = np.array(train_data[features])\n",
    "np_train_data = np.array(pd.concat([train_data[features], data_XRs, data_YRs], axis=1))\n",
    "\n",
    "#np_train_data = np.array(pd.concat([data_XRs, data_YRs], axis=1))\n",
    "\n",
    "\n",
    "\n",
    "#pd.concat([data, years, months, days, daysofweek, hours, districts], axis=1)\n",
    "#print np_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 295)\n",
      "(878049,)\n",
      "# Neural Network with 167539 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input      295\n",
      "  1  hidden     500\n",
      "  2  output      39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.63132\u001b[0m       \u001b[32m2.62853\u001b[0m      1.00106      0.22558  29.17s\n",
      "      2       \u001b[36m2.52393\u001b[0m       \u001b[32m2.60553\u001b[0m      0.96868      0.22639  28.61s\n",
      "      3       \u001b[36m2.49870\u001b[0m       \u001b[32m2.59233\u001b[0m      0.96388      0.22789  31.51s\n",
      "      4       \u001b[36m2.48395\u001b[0m       \u001b[32m2.58444\u001b[0m      0.96112      0.22916  26.67s\n",
      "      5       \u001b[36m2.47430\u001b[0m       \u001b[32m2.57896\u001b[0m      0.95942      0.23070  27.25s\n",
      "      6       \u001b[36m2.46697\u001b[0m       \u001b[32m2.57455\u001b[0m      0.95822      0.23279  28.06s\n",
      "      7       \u001b[36m2.46080\u001b[0m       \u001b[32m2.57073\u001b[0m      0.95724      0.23409  27.99s\n",
      "      8       \u001b[36m2.45531\u001b[0m       \u001b[32m2.56732\u001b[0m      0.95637      0.23547  27.81s\n",
      "      9       \u001b[36m2.45030\u001b[0m       \u001b[32m2.56427\u001b[0m      0.95556      0.23653  27.60s\n",
      "     10       \u001b[36m2.44568\u001b[0m       \u001b[32m2.56148\u001b[0m      0.95479      0.23744  26.93s\n",
      "     11       \u001b[36m2.44139\u001b[0m       \u001b[32m2.55897\u001b[0m      0.95405      0.23859  26.67s\n",
      "     12       \u001b[36m2.43737\u001b[0m       \u001b[32m2.55657\u001b[0m      0.95338      0.23904  29.72s\n",
      "     13       \u001b[36m2.43360\u001b[0m       \u001b[32m2.55431\u001b[0m      0.95274      0.23985  27.24s\n",
      "     14       \u001b[36m2.43002\u001b[0m       \u001b[32m2.55220\u001b[0m      0.95213      0.24055  27.29s\n",
      "     15       \u001b[36m2.42661\u001b[0m       \u001b[32m2.55019\u001b[0m      0.95154      0.24150  29.07s\n",
      "     16       \u001b[36m2.42333\u001b[0m       \u001b[32m2.54828\u001b[0m      0.95097      0.24213  30.24s\n",
      "     17       \u001b[36m2.42017\u001b[0m       \u001b[32m2.54638\u001b[0m      0.95043      0.24267  27.23s\n",
      "     18       \u001b[36m2.41712\u001b[0m       \u001b[32m2.54460\u001b[0m      0.94990      0.24355  27.33s\n",
      "     19       \u001b[36m2.41417\u001b[0m       \u001b[32m2.54290\u001b[0m      0.94938      0.24435  27.52s\n",
      "     20       \u001b[36m2.41131\u001b[0m       \u001b[32m2.54123\u001b[0m      0.94888      0.24495  27.29s\n",
      "     21       \u001b[36m2.40854\u001b[0m       \u001b[32m2.53967\u001b[0m      0.94837      0.24582  27.10s\n",
      "     22       \u001b[36m2.40586\u001b[0m       \u001b[32m2.53816\u001b[0m      0.94788      0.24640  27.91s\n",
      "     23       \u001b[36m2.40324\u001b[0m       \u001b[32m2.53670\u001b[0m      0.94739      0.24627  28.08s\n",
      "     24       \u001b[36m2.40069\u001b[0m       \u001b[32m2.53529\u001b[0m      0.94691      0.24670  4407.24s\n",
      "     25       \u001b[36m2.39821\u001b[0m       \u001b[32m2.53401\u001b[0m      0.94641      0.24680  28.19s\n",
      "     26       \u001b[36m2.39579\u001b[0m       \u001b[32m2.53274\u001b[0m      0.94593      0.24729  29.24s\n",
      "     27       \u001b[36m2.39343\u001b[0m       \u001b[32m2.53151\u001b[0m      0.94546      0.24782  29.82s\n",
      "     28       \u001b[36m2.39113\u001b[0m       \u001b[32m2.53035\u001b[0m      0.94498      0.24820  30.04s\n",
      "     29       \u001b[36m2.38889\u001b[0m       \u001b[32m2.52927\u001b[0m      0.94450      0.24825  30.78s\n",
      "     30       \u001b[36m2.38669\u001b[0m       \u001b[32m2.52817\u001b[0m      0.94404      0.24859  30.41s\n",
      "     31       \u001b[36m2.38454\u001b[0m       \u001b[32m2.52710\u001b[0m      0.94359      0.24884  31.39s\n",
      "     32       \u001b[36m2.38243\u001b[0m       \u001b[32m2.52611\u001b[0m      0.94312      0.24911  27.53s\n",
      "     33       \u001b[36m2.38036\u001b[0m       \u001b[32m2.52514\u001b[0m      0.94267      0.24948  28.76s\n",
      "     34       \u001b[36m2.37834\u001b[0m       \u001b[32m2.52425\u001b[0m      0.94220      0.24961  49.17s\n",
      "     35       \u001b[36m2.37637\u001b[0m       \u001b[32m2.52341\u001b[0m      0.94173      0.24987  29.33s"
     ]
    }
   ],
   "source": [
    "# Simple net... for some reason this is currently just picking the most common class for everything\n",
    "num_features = np_train_data.shape[1]\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, num_features),  # 3 input pixels per batch\n",
    "    hidden_num_units=500,  # number of units in hidden layer\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    output_num_units=39,  # 39 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.002,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "print np_train_data.shape\n",
    "print train_labels.shape\n",
    "#print len(train_data.columns)\n",
    "net1.fit(np_train_data, train_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAESCAYAAADjS5I+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCknSTBYKSdJM/x8PHFxTD61U4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123089bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = np.array([i[\"train_loss\"] for i in net1.train_history_])\n",
    "valid_loss = np.array([i[\"valid_loss\"] for i in net1.train_history_])\n",
    "plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(1e-0, 1e1)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "# Looks pretty bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1513\n",
      "          1       0.18      0.02      0.03     76876\n",
      "          2       0.00      0.00      0.00       406\n",
      "          3       0.00      0.00      0.00       289\n",
      "          4       0.10      0.00      0.00     36755\n",
      "          5       0.00      0.00      0.00      4320\n",
      "          6       0.00      0.00      0.00      2268\n",
      "          7       0.33      0.04      0.07     53971\n",
      "          8       0.00      0.00      0.00      4280\n",
      "          9       0.00      0.00      0.00      1166\n",
      "         10       0.00      0.00      0.00       256\n",
      "         11       0.00      0.00      0.00       491\n",
      "         12       0.00      0.00      0.00     10609\n",
      "         13       0.00      0.00      0.00     16679\n",
      "         14       0.00      0.00      0.00       146\n",
      "         15       0.00      0.00      0.00      2341\n",
      "         16       0.24      0.82      0.37    174900\n",
      "         17       0.00      0.00      0.00      1903\n",
      "         18       0.00      0.00      0.00      1225\n",
      "         19       0.40      0.12      0.18     25989\n",
      "         20       0.13      0.27      0.17     92304\n",
      "         21       0.20      0.09      0.12    126182\n",
      "         22       0.00      0.00      0.00        22\n",
      "         23       0.42      0.23      0.29      7484\n",
      "         24       0.00      0.00      0.00      3138\n",
      "         25       0.00      0.00      0.00     23000\n",
      "         26       0.00      0.00      0.00      1946\n",
      "         27       0.00      0.00      0.00      9985\n",
      "         28       0.00      0.00      0.00      4388\n",
      "         29       0.00      0.00      0.00       148\n",
      "         30       0.00      0.00      0.00      4540\n",
      "         31       0.00      0.00      0.00       508\n",
      "         32       0.00      0.00      0.00     31414\n",
      "         33       0.00      0.00      0.00         6\n",
      "         34       0.00      0.00      0.00      7326\n",
      "         35       0.02      0.00      0.00     44725\n",
      "         36       0.00      0.00      0.00     53781\n",
      "         37       0.11      0.00      0.00     42214\n",
      "         38       0.00      0.00      0.00      8555\n",
      "\n",
      "avg / total       0.15      0.21      0.12    878049\n",
      "\n",
      "The accuracy is: 0.214477779714\n"
     ]
    }
   ],
   "source": [
    "train_pred = net1.predict(np_train_data)\n",
    "print(classification_report(train_labels_int, train_pred))\n",
    "print 'The accuracy is:', accuracy_score(train_labels_int, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 619 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input         7\n",
      "  1  dense0       10\n",
      "  2  dropout      10\n",
      "  3  dense1       10\n",
      "  4  output       39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m4.14217\u001b[0m       \u001b[32m2.70658\u001b[0m      1.53041      0.19904  2.46s\n",
      "      2       \u001b[36m2.64476\u001b[0m       \u001b[32m2.70492\u001b[0m      0.97776      0.19904  2.82s\n",
      "      3       \u001b[36m2.64386\u001b[0m       \u001b[32m2.70447\u001b[0m      0.97759      0.19904  2.76s\n",
      "      4       \u001b[36m2.64356\u001b[0m       \u001b[32m2.70428\u001b[0m      0.97755      0.19904  2.82s\n",
      "      5       \u001b[36m2.64343\u001b[0m       \u001b[32m2.70418\u001b[0m      0.97753      0.19904  2.74s\n",
      "      6       \u001b[36m2.64335\u001b[0m       \u001b[32m2.70412\u001b[0m      0.97753      0.19904  2.90s\n",
      "      7       \u001b[36m2.64330\u001b[0m       \u001b[32m2.70408\u001b[0m      0.97752      0.19904  2.99s\n",
      "      8       \u001b[36m2.64327\u001b[0m       \u001b[32m2.70406\u001b[0m      0.97752      0.19904  2.91s\n",
      "      9       \u001b[36m2.64324\u001b[0m       \u001b[32m2.70404\u001b[0m      0.97752      0.19904  2.77s\n",
      "     10       \u001b[36m2.64323\u001b[0m       \u001b[32m2.70402\u001b[0m      0.97752      0.19904  2.76s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c727450>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c7273d0>,\n",
       "     custom_score=None, dense0_num_units=10, dense1_num_units=10,\n",
       "     dropout_p=0.5, input_shape=(None, 7),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('dense0', <class 'lasagne.layers.dense.DenseLayer'>), ('dropout', <class 'lasagne.layers.noise.DropoutLayer'>), ('dense1', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=10, more_params={},\n",
       "     objective=<function objective at 0x10c72a938>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c645a28>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x1290f2d40>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x1290f2d88>],\n",
       "     output_nonlinearity=<function softmax at 0x10c4fa140>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c727490>,\n",
       "     update=<function nesterov_momentum at 0x10c656758>,\n",
       "     update_learning_rate=0.02, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tried a more complicated net with layers... still doing the same thing.\n",
    "net2 = NeuralNet(\n",
    "    layers=[  # more layers\n",
    "        ('input', layers.InputLayer),\n",
    "        ('dense0', layers.DenseLayer),\n",
    "        ('dropout', layers.DropoutLayer),\n",
    "        ('dense1', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer)\n",
    "    ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, 7),  # 3 input pixels per batch\n",
    "    dense0_num_units=10,  # number of units in hidden layer\n",
    "    dropout_p=0.5,  # Not sure what this does.....\n",
    "    dense1_num_units=10,  # number of units in hidden layer\n",
    "    output_num_units=39,  # 39 target values\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.02,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=10,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "net2.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "Old code below here\n",
    "____\n",
    "____\n",
    "____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 254)\n",
      "(878049,)\n",
      "# Neural Network with 147039 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  ------  ------\n",
      "  0  input      254\n",
      "  1  hidden     500\n",
      "  2  output      39\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.67321\u001b[0m       \u001b[32m2.66736\u001b[0m      1.00219      0.20197  24.90s\n",
      "      2       \u001b[36m2.56639\u001b[0m       \u001b[32m2.64605\u001b[0m      0.96990      0.20978  24.59s\n",
      "      3       \u001b[36m2.54176\u001b[0m       \u001b[32m2.63234\u001b[0m      0.96559      0.21508  24.00s\n",
      "      4       \u001b[36m2.52726\u001b[0m       \u001b[32m2.62335\u001b[0m      0.96337      0.21664  24.68s\n",
      "      5       \u001b[36m2.51784\u001b[0m       \u001b[32m2.61697\u001b[0m      0.96212      0.21816  24.39s\n",
      "      6       \u001b[36m2.51080\u001b[0m       \u001b[32m2.61196\u001b[0m      0.96127      0.22045  23.91s\n",
      "      7       \u001b[36m2.50493\u001b[0m       \u001b[32m2.60775\u001b[0m      0.96057      0.22372  23.92s\n",
      "      8       \u001b[36m2.49969\u001b[0m       \u001b[32m2.60389\u001b[0m      0.95998      0.22694  23.90s\n",
      "      9       \u001b[36m2.49486\u001b[0m       \u001b[32m2.60038\u001b[0m      0.95942      0.22709  24.10s\n",
      "     10       \u001b[36m2.49034\u001b[0m       \u001b[32m2.59712\u001b[0m      0.95889      0.22724  23.78s\n",
      "     11       \u001b[36m2.48610\u001b[0m       \u001b[32m2.59406\u001b[0m      0.95838      0.22909  23.70s\n",
      "     12       \u001b[36m2.48213\u001b[0m       \u001b[32m2.59122\u001b[0m      0.95790      0.23008  23.79s\n",
      "     13       \u001b[36m2.47841\u001b[0m       \u001b[32m2.58860\u001b[0m      0.95743      0.23017  24.26s\n",
      "     14       \u001b[36m2.47490\u001b[0m       \u001b[32m2.58617\u001b[0m      0.95698      0.23180  24.22s\n",
      "     15       \u001b[36m2.47159\u001b[0m       \u001b[32m2.58384\u001b[0m      0.95656      0.23283  23.58s\n",
      "     16       \u001b[36m2.46845\u001b[0m       \u001b[32m2.58163\u001b[0m      0.95616      0.23391  24.92s\n",
      "     17       \u001b[36m2.46545\u001b[0m       \u001b[32m2.57954\u001b[0m      0.95577      0.23471  23.68s\n",
      "     18       \u001b[36m2.46256\u001b[0m       \u001b[32m2.57753\u001b[0m      0.95539      0.23510  23.62s\n",
      "     19       \u001b[36m2.45978\u001b[0m       \u001b[32m2.57558\u001b[0m      0.95504      0.23541  23.58s\n",
      "     20       \u001b[36m2.45708\u001b[0m       \u001b[32m2.57364\u001b[0m      0.95471      0.23588  24.69s\n",
      "     21       \u001b[36m2.45444\u001b[0m       \u001b[32m2.57175\u001b[0m      0.95438      0.23620  23.78s\n",
      "     22       \u001b[36m2.45186\u001b[0m       \u001b[32m2.56992\u001b[0m      0.95406      0.23663  23.62s\n",
      "     23       \u001b[36m2.44935\u001b[0m       \u001b[32m2.56819\u001b[0m      0.95373      0.23777  25.07s\n",
      "     24       \u001b[36m2.44691\u001b[0m       \u001b[32m2.56647\u001b[0m      0.95341      0.23841  25.80s\n",
      "     25       \u001b[36m2.44452\u001b[0m       \u001b[32m2.56480\u001b[0m      0.95310      0.23901  24.93s\n",
      "     26       \u001b[36m2.44220\u001b[0m       \u001b[32m2.56316\u001b[0m      0.95281      0.24013  25.19s\n",
      "     27       \u001b[36m2.43994\u001b[0m       \u001b[32m2.56159\u001b[0m      0.95251      0.24066  25.25s\n",
      "     28       \u001b[36m2.43773\u001b[0m       \u001b[32m2.56006\u001b[0m      0.95222      0.24114  28.35s\n",
      "     29       \u001b[36m2.43559\u001b[0m       \u001b[32m2.55862\u001b[0m      0.95192      0.24176  25.75s\n",
      "     30       \u001b[36m2.43351\u001b[0m       \u001b[32m2.55727\u001b[0m      0.95161      0.24204  24.77s\n",
      "     31       \u001b[36m2.43148\u001b[0m       \u001b[32m2.55592\u001b[0m      0.95131      0.24335  24.81s\n",
      "     32       \u001b[36m2.42950\u001b[0m       \u001b[32m2.55463\u001b[0m      0.95102      0.24384  24.97s\n",
      "     33       \u001b[36m2.42758\u001b[0m       \u001b[32m2.55342\u001b[0m      0.95072      0.24374  24.77s\n",
      "     34       \u001b[36m2.42571\u001b[0m       \u001b[32m2.55224\u001b[0m      0.95043      0.24414  25.17s\n",
      "     35       \u001b[36m2.42390\u001b[0m       \u001b[32m2.55107\u001b[0m      0.95015      0.24418  24.83s\n",
      "     36       \u001b[36m2.42213\u001b[0m       \u001b[32m2.54999\u001b[0m      0.94986      0.24461  24.75s\n",
      "     37       \u001b[36m2.42041\u001b[0m       \u001b[32m2.54899\u001b[0m      0.94956      0.24480  24.88s\n",
      "     38       \u001b[36m2.41873\u001b[0m       \u001b[32m2.54804\u001b[0m      0.94925      0.24496  24.67s\n",
      "     39       \u001b[36m2.41709\u001b[0m       \u001b[32m2.54712\u001b[0m      0.94895      0.24556  24.66s\n",
      "     40       \u001b[36m2.41551\u001b[0m       \u001b[32m2.54626\u001b[0m      0.94865      0.24607  24.67s\n",
      "     41       \u001b[36m2.41395\u001b[0m       \u001b[32m2.54540\u001b[0m      0.94836      0.24638  24.67s\n",
      "     42       \u001b[36m2.41244\u001b[0m       \u001b[32m2.54461\u001b[0m      0.94806      0.24606  24.66s\n",
      "     43       \u001b[36m2.41097\u001b[0m       \u001b[32m2.54381\u001b[0m      0.94778      0.24603  25.24s\n",
      "     44       \u001b[36m2.40954\u001b[0m       \u001b[32m2.54310\u001b[0m      0.94748      0.24644  24.95s\n",
      "     45       \u001b[36m2.40814\u001b[0m       \u001b[32m2.54240\u001b[0m      0.94719      0.24649  24.68s\n",
      "     46       \u001b[36m2.40678\u001b[0m       \u001b[32m2.54175\u001b[0m      0.94690      0.24660  24.63s\n",
      "     47       \u001b[36m2.40544\u001b[0m       \u001b[32m2.54116\u001b[0m      0.94659      0.24649  24.68s\n",
      "     48       \u001b[36m2.40415\u001b[0m       \u001b[32m2.54059\u001b[0m      0.94629      0.24658  24.62s\n",
      "     49       \u001b[36m2.40289\u001b[0m       \u001b[32m2.54006\u001b[0m      0.94600      0.24695  24.51s\n",
      "     50       \u001b[36m2.40166\u001b[0m       \u001b[32m2.53956\u001b[0m      0.94570      0.24715  24.57s\n",
      "     51       \u001b[36m2.40046\u001b[0m       \u001b[32m2.53906\u001b[0m      0.94541      0.24739  25.44s\n",
      "     52       \u001b[36m2.39929\u001b[0m       \u001b[32m2.53859\u001b[0m      0.94513      0.24753  24.69s\n",
      "     53       \u001b[36m2.39815\u001b[0m       \u001b[32m2.53816\u001b[0m      0.94484      0.24721  24.60s\n",
      "     54       \u001b[36m2.39703\u001b[0m       \u001b[32m2.53767\u001b[0m      0.94458      0.24727  24.56s\n",
      "     55       \u001b[36m2.39594\u001b[0m       \u001b[32m2.53729\u001b[0m      0.94429      0.24735  24.55s\n",
      "     56       \u001b[36m2.39488\u001b[0m       \u001b[32m2.53686\u001b[0m      0.94404      0.24731  24.59s\n",
      "     57       \u001b[36m2.39385\u001b[0m       \u001b[32m2.53648\u001b[0m      0.94377      0.24735  24.58s\n",
      "     58       \u001b[36m2.39283\u001b[0m       \u001b[32m2.53614\u001b[0m      0.94350      0.24798  24.62s\n",
      "     59       \u001b[36m2.39184\u001b[0m       \u001b[32m2.53578\u001b[0m      0.94324      0.24795  24.66s\n",
      "     60       \u001b[36m2.39086\u001b[0m       \u001b[32m2.53547\u001b[0m      0.94297      0.24811  25.02s\n",
      "     61       \u001b[36m2.38991\u001b[0m       \u001b[32m2.53518\u001b[0m      0.94270      0.24822  24.82s\n",
      "     62       \u001b[36m2.38898\u001b[0m       \u001b[32m2.53494\u001b[0m      0.94242      0.24837  24.57s\n",
      "     63       \u001b[36m2.38806\u001b[0m       \u001b[32m2.53467\u001b[0m      0.94216      0.24831  24.70s\n",
      "     64       \u001b[36m2.38717\u001b[0m       \u001b[32m2.53440\u001b[0m      0.94191      0.24835  25.59s\n",
      "     65       \u001b[36m2.38629\u001b[0m       \u001b[32m2.53419\u001b[0m      0.94164      0.24840  24.60s\n",
      "     66       \u001b[36m2.38543\u001b[0m       \u001b[32m2.53396\u001b[0m      0.94138      0.24903  25.10s\n",
      "     67       \u001b[36m2.38458\u001b[0m       \u001b[32m2.53375\u001b[0m      0.94113      0.24913  24.78s\n",
      "     68       \u001b[36m2.38375\u001b[0m       \u001b[32m2.53356\u001b[0m      0.94087      0.24907  24.57s\n",
      "     69       \u001b[36m2.38294\u001b[0m       \u001b[32m2.53333\u001b[0m      0.94063      0.24904  24.59s\n",
      "     70       \u001b[36m2.38215\u001b[0m       \u001b[32m2.53317\u001b[0m      0.94038      0.24907  24.57s\n",
      "     71       \u001b[36m2.38137\u001b[0m       \u001b[32m2.53304\u001b[0m      0.94012      0.24880  25.27s\n",
      "     72       \u001b[36m2.38061\u001b[0m       \u001b[32m2.53286\u001b[0m      0.93989      0.24857  24.75s\n",
      "     73       \u001b[36m2.37986\u001b[0m       \u001b[32m2.53269\u001b[0m      0.93966      0.24847  24.71s\n",
      "     74       \u001b[36m2.37912\u001b[0m       \u001b[32m2.53257\u001b[0m      0.93941      0.24845  24.72s\n",
      "     75       \u001b[36m2.37840\u001b[0m       \u001b[32m2.53245\u001b[0m      0.93917      0.24846  24.76s\n",
      "     76       \u001b[36m2.37768\u001b[0m       \u001b[32m2.53237\u001b[0m      0.93892      0.24834  24.58s\n",
      "     77       \u001b[36m2.37698\u001b[0m       \u001b[32m2.53223\u001b[0m      0.93869      0.24832  24.63s\n",
      "     78       \u001b[36m2.37629\u001b[0m       \u001b[32m2.53213\u001b[0m      0.93846      0.24812  24.67s\n",
      "     79       \u001b[36m2.37562\u001b[0m       \u001b[32m2.53201\u001b[0m      0.93824      0.24816  24.54s\n",
      "     80       \u001b[36m2.37496\u001b[0m       \u001b[32m2.53189\u001b[0m      0.93802      0.24808  24.60s\n",
      "     81       \u001b[36m2.37430\u001b[0m       \u001b[32m2.53183\u001b[0m      0.93778      0.24783  24.69s\n",
      "     82       \u001b[36m2.37367\u001b[0m       \u001b[32m2.53174\u001b[0m      0.93756      0.24785  25.10s\n",
      "     83       \u001b[36m2.37304\u001b[0m       \u001b[32m2.53170\u001b[0m      0.93733      0.24785  26.41s\n",
      "     84       \u001b[36m2.37242\u001b[0m       \u001b[32m2.53166\u001b[0m      0.93710      0.24759  25.89s\n",
      "     85       \u001b[36m2.37181\u001b[0m       \u001b[32m2.53157\u001b[0m      0.93689      0.24756  24.74s\n",
      "     86       \u001b[36m2.37121\u001b[0m       \u001b[32m2.53151\u001b[0m      0.93668      0.24748  24.69s\n",
      "     87       \u001b[36m2.37063\u001b[0m       \u001b[32m2.53150\u001b[0m      0.93645      0.24736  24.80s\n",
      "     88       \u001b[36m2.37005\u001b[0m       \u001b[32m2.53145\u001b[0m      0.93624      0.24714  24.61s\n",
      "     89       \u001b[36m2.36947\u001b[0m       \u001b[32m2.53137\u001b[0m      0.93604      0.24712  24.69s\n",
      "     90       \u001b[36m2.36890\u001b[0m       \u001b[32m2.53135\u001b[0m      0.93582      0.24704  24.59s\n",
      "     91       \u001b[36m2.36834\u001b[0m       \u001b[32m2.53133\u001b[0m      0.93561      0.24733  24.78s\n",
      "     92       \u001b[36m2.36779\u001b[0m       \u001b[32m2.53131\u001b[0m      0.93540      0.24744  24.56s\n",
      "     93       \u001b[36m2.36725\u001b[0m       \u001b[32m2.53127\u001b[0m      0.93520      0.24751  25.47s\n",
      "     94       \u001b[36m2.36672\u001b[0m       \u001b[32m2.53124\u001b[0m      0.93500      0.24753  25.32s\n",
      "     95       \u001b[36m2.36619\u001b[0m       \u001b[32m2.53119\u001b[0m      0.93481      0.24747  24.95s\n",
      "     96       \u001b[36m2.36567\u001b[0m       \u001b[32m2.53118\u001b[0m      0.93461      0.24734  26.04s\n",
      "     97       \u001b[36m2.36516\u001b[0m       \u001b[32m2.53116\u001b[0m      0.93442      0.24746  25.10s\n",
      "     98       \u001b[36m2.36466\u001b[0m       2.53118      0.93421      0.24737  24.98s\n",
      "     99       \u001b[36m2.36416\u001b[0m       2.53117      0.93402      0.24735  24.71s\n",
      "    100       \u001b[36m2.36367\u001b[0m       2.53118      0.93382      0.24713  24.79s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc1d0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10c3cc150>,\n",
       "     custom_score=None, hidden_num_units=500, input_shape=(None, 254),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x10c3c5c80>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10c1e2c80>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x112c910e0>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x113a6a950>],\n",
       "     output_nonlinearity=<function softmax at 0x10c09c398>,\n",
       "     output_num_units=39, regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x10c3cc210>,\n",
       "     update=<function nesterov_momentum at 0x10c1f59b0>,\n",
       "     update_learning_rate=0.002, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_train_data = np.array(pd.concat([data_XRs, data_YRs], axis=1))\n",
    "num_features = np_train_data.shape[1]\n",
    "#The accuracy is: 0.26692018327\n",
    "\n",
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, num_features),  # 3 input pixels per batch\n",
    "    hidden_num_units=500,  # number of units in hidden layer\n",
    "    output_nonlinearity=nonlinearities.softmax,\n",
    "    output_num_units=39,  # 39 target values\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.002,\n",
    "    update_momentum=0.9,\n",
    "\n",
    "    regression=False,  # flag to indicate we're not dealing with regression problem\n",
    "    max_epochs=100,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "print np_train_data.shape\n",
    "print train_labels.shape\n",
    "#print len(train_data.columns)\n",
    "net1.fit(np_train_data, train_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "      1       2.61487       2.69044      0.97191      0.20939  32.26s\n",
    "      2       2.51820       2.70484      0.93099      0.20054  34.48s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BernoulliRBM' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-12d76fb973a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#NNmodel = BernoulliRBM()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#NNmodel.fit(train_data, train_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdev_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"The NN with normalized DateDiff, X and Y (k=1) scores: {:.6f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BernoulliRBM' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "#OLD - NOT USING Fit a basic RBM\n",
    "\n",
    "#NNmodel = BernoulliRBM()\n",
    "#NNmodel.fit(train_data, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.]\n",
      "[ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Convert to Numpy Format\n",
    "# TODO: Add more features here\n",
    "train_data = np.array(train[['DateDiff','X','Y']].values)\n",
    "train_labels = np.array(train[['Category']].values.ravel())\n",
    "\n",
    "dev_data = np.array(dev[['DateDiff','X','Y']].values)\n",
    "dev_labels = np.array(dev[['Category']].values.ravel())\n",
    "\n",
    "full_data = np.array(data[['DateDiff','X','Y']].values)\n",
    "full_labels = np.array(data[['Category']].values.ravel())\n",
    "\n",
    "test_data = np.array(test[['DateDiff','X','Y']].values)\n",
    "\n",
    "# Normalize Data to Between 0-1\n",
    "# a + (x-A)*(b-a)/(B-A) \n",
    "# TODO: Fix normalization to kick out \"bad\" x/y\n",
    "train_normed = 0 + (np.abs(train_data) - np.abs(train_data).min(axis=0))*(1-0)/(np.abs(train_data).max(axis=0) - np.abs(train_data).min(axis=0)) \n",
    "dev_normed = 0 + (np.abs(dev_data) - np.abs(dev_data).min(axis=0))*(1-0)/(np.abs(dev_data).max(axis=0) - np.abs(dev_data).min(axis=0)) \n",
    "\n",
    "print train_normed.min(axis=0)\n",
    "print train_normed.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Below this point is from KNN - here to steal bits from while I work on NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for each k value was [mean: 0.00303, std: 0.00382, params: {'n_neighbors': 1}, mean: 0.00314, std: 0.00389, params: {'n_neighbors': 2}, mean: 0.00300, std: 0.00380, params: {'n_neighbors': 3}, mean: 0.00302, std: 0.00378, params: {'n_neighbors': 4}, mean: 0.00299, std: 0.00371, params: {'n_neighbors': 5}, mean: 0.00300, std: 0.00373, params: {'n_neighbors': 6}, mean: 0.00297, std: 0.00372, params: {'n_neighbors': 7}, mean: 0.00297, std: 0.00371, params: {'n_neighbors': 8}, mean: 0.00295, std: 0.00369, params: {'n_neighbors': 9}, mean: 0.00295, std: 0.00368, params: {'n_neighbors': 10}] \n",
      "The best k value was {'n_neighbors': 2} with accuracy 0.0031\n"
     ]
    }
   ],
   "source": [
    "# Use GridSearchCV to find a good number of neighbors.\n",
    "#ks = {'n_neighbors': range(1,4)}\n",
    "ks = {'n_neighbors': [1,2,3,4,5,6,7,8,9,10]}\n",
    "KNNGridSearch = GridSearchCV(KNeighborsClassifier(), ks, scoring='f1_weighted')\n",
    "KNNGridSearch.fit(train_data, train_labels)\n",
    "\n",
    "# Report out on the accuracies    \n",
    "print \"The scores for each k value was %s \" % (KNNGridSearch.grid_scores_)\n",
    "print \"The best k value was %s with accuracy %.4f\" % (KNNGridSearch.best_params_, KNNGridSearch.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KNN with DateDiff, X and Y (k=2) scores: 0.220072\n"
     ]
    }
   ],
   "source": [
    "# Try k = 2\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=1)\n",
    "KNNmodel.fit(train_data, train_labels)\n",
    "dev_predict = KNNmodel.predict(dev_data)\n",
    "print \"The KNN with DateDiff, X and Y (k=2) scores: {:.6f}\".format(metrics.f1_score(dev_labels, dev_predict, average='weighted'))\n",
    "\n",
    "\n",
    "# Tried a few tests (including the above). So far k=1 seems best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we've sorted out a naive alg to run. Let's train on all train, then predict on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(preds):\n",
    "    labels = [\"Id\",\n",
    "                \"ARSON\",\n",
    "                \"ASSAULT\",\n",
    "                \"BAD CHECKS\",\n",
    "                \"BRIBERY\",\n",
    "                \"BURGLARY\",\n",
    "                \"DISORDERLY CONDUCT\",\n",
    "                \"DRIVING UNDER THE INFLUENCE\",\n",
    "                \"DRUG/NARCOTIC\",\n",
    "                \"DRUNKENNESS\",\n",
    "                \"EMBEZZLEMENT\",\n",
    "                \"EXTORTION\",\n",
    "                \"FAMILY OFFENSES\",\n",
    "                \"FORGERY/COUNTERFEITING\",\n",
    "                \"FRAUD\",\n",
    "                \"GAMBLING\",\n",
    "                \"KIDNAPPING\",\n",
    "                \"LARCENY/THEFT\",\n",
    "                \"LIQUOR LAWS\",\n",
    "                \"LOITERING\",\n",
    "                \"MISSING PERSON\",\n",
    "                \"NON-CRIMINAL\",\n",
    "                \"OTHER OFFENSES\",\n",
    "                \"PORNOGRAPHY/OBSCENE MAT\",\n",
    "                \"PROSTITUTION\",\n",
    "                \"RECOVERED VEHICLE\",\n",
    "                \"ROBBERY\",\n",
    "                \"RUNAWAY\",\n",
    "                \"SECONDARY CODES\",\n",
    "                \"SEX OFFENSES FORCIBLE\",\n",
    "                \"SEX OFFENSES NON FORCIBLE\",\n",
    "                \"STOLEN PROPERTY\",\n",
    "                \"SUICIDE\",\n",
    "                \"SUSPICIOUS OCC\",\n",
    "                \"TREA\",\n",
    "                \"TRESPASS\",\n",
    "                \"VANDALISM\",\n",
    "                \"VEHICLE THEFT\",\n",
    "                \"WARRANTS\",\n",
    "                \"WEAPON LAWS\"\n",
    "              ]\n",
    "    head_str = ','.join(labels)\n",
    "\n",
    "    num_cats = len(labels)\n",
    "    \n",
    "    # Make a dummy row to append to\n",
    "    ids = np.arange(preds.shape[0])[np.newaxis].transpose()\n",
    "    \n",
    "    results = np.column_stack((ids, preds))\n",
    "\n",
    "    # Write results to csv\n",
    "    np.savetxt('sample.csv', results, fmt='%d', delimiter=',', header=head_str, comments='')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we've done this, let's run the KNN on the full train, apply to the test, then format.\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=1)\n",
    "KNNmodel.fit(full_data, full_labels)\n",
    "dev_predict = KNNmodel.predict_proba(test_data).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = create_submission(dev_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884262, 40)\n"
     ]
    }
   ],
   "source": [
    "print results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
